* # 과목 Ⅰ. 데이터 모델링의 이해
   + ## 제1장 데이터 모델링의 이해
     + ### 제1절 데이터 모델의 이해
       + #### 1. 모델링의 이해
         + ##### 가. 모델링의 정의
           > * 가설적 또는 일정 양식에 맞춘 표현
         + ##### 나. 모델링의 특징
           > * 추상화 : 현실세계를 일정한 형식에 맞춰 표현
           > * 단순화 : 현실세계를 약속한 규약에 의해 제한된 표기
           > * 명확화 : 애매모호함 제거
         + ##### 다. 모델링의 세 가지 관점
           > 데이터 관점, 프로세스 관점, 데이터와 프로세스의 상관관점
       + #### 2. 데이터 모델의 기본 개념의 이해
         + ##### 가. 모델링의 정의
         + ##### 나. 데이터 모델이 제공하는 기능
           > 가시화, 명세화, 구조화, 문서화
       + #### 3. 데이터 모델링의 중요성 및 유의점
         + ##### 가. 파급효과(Leverage)
         + ##### 나. 복잡한 정보 요구 사항의 간결한 표현
         + ##### 다. 데이터 품질(Data Quality)
           > 데이터 = 기업의 중요 자산
       + #### 4. 데이터 모델링의 3단계 진행
         + ##### 가. 개념적 데이터 모델링(Conceptual Data Modeling)
           > 추상적. 업무중심적. 포괄전. 전사적데이터 모델링, EA수립시.
         + ##### 나. 논리적 데이터 모델링(Logical Data Modeling)
           > KEY, 속성, 관계 표현. 재사용성 높음. **정규화**진행.
         + ##### 다. 물리적 데이터 모델링(Physical Data Modeling)
           > 실제 DB 이식 가능할 수준의 설계. 물리적 스키마
       + #### 5. 프로젝트 생명주기(Life Cycle)에서 데이터 모델링
         ![IMG](/images_files/SQL_006.jpg)
       + #### 6. 데이터 모델링에서 데이터독립성의 이해
         + ##### 가. 데이터독립성의 필요성
         + ##### 나. 데이터베이스 3단계 구조
           > 외부단계, 개념적 단계, 내부적 단계
         + ##### 다. 데이터독립성 요소
           ![IMG](/images_files/SQL_009.jpg)
         + ##### 라. 두 영역의 데이터독립성
           ![IMG](/images_files/SQL_010.jpg)
         + ##### 마. 사상(Mapping)
           ![IMG](/images_files/SQL_011.jpg)
       + #### 7. 데이터 모델링의 중요한 세 가지 개념
         + ##### 가. 데이터 모델링의 세 가지 요소
          > 1) 업무가 관여하는 어떤 것(Things) : 이주일 심순애
          > 2) 어떤 것이 가지는 성격(Attributes) : 친절, 세심하며 활발함
          > 3) 업무가 관여하는 어떤 것 간의 관계(Relationships) : 연인사이
         + ##### 나. 단수와 집합(복수)의 명명
          ![IMG](/images_files/SQL_013.jpg)
       + #### 8. 데이터 모델링의 이해관계자
         + ##### 가. 이해관계자의 데이터 모델링 중요성 인식
         + ##### 나. 데이터 모델링의 이해관계자
       + #### 9. 데이터 모델의 표기법인 ERD의 이해
         + ##### 가. 데이터 모델 표기법
         + ##### 나. ERD(Entity Relationship Diagram) 표기법을 이용하여 모델링하는 방법
           + ###### 1) ERD 작업순서
           + ###### 2) 엔터티 배치
           + ###### 3) ERD 관계의 연결
           + ###### 4) ERD 관계명의 표시
           + ###### 5) ERD 관계 관계차수와 선택성 표시
       + #### 10. 좋은 데이터 모델의 요소
         + ##### 가. 완전성(Completeness)
           > 모든 데이터가 데이터 모델에 정의되어 있어야 함.
         + ##### 나. 중복배제(Non-Redundancy)
           > 한번만 기록(ex 나이,생년월일)
         + ##### 다. 업무규칙(Business Rules)
         + ##### 라. 데이터 재사용(Data Reusability)
           > 확장성을 위해 통합, 재활용할것.
         + ##### 마. 의사소통(Communication)
         + ##### 바. 통합성(Integration)
           > 조직의 전체에서 한번만 정의하고 참조,활용.
     + ### 제2절 엔터티(Entity)
       + #### 1. 엔터티의 개념
       + #### 2. 엔터티와 인스턴스에 대한 내용과 표기법
         ![IMG](images_files/SQL_023.jpg)
       + #### 3. 엔터티의 특징
         + ##### 가. 업무에서 필요로 하는 정보
           > 병원의 환자엔터티, 회사의 환자엔터티
         + ##### 나. 식별이 가능해야 함
           > 직원엔터디 : 사번(식별자o) 이름(식별자x)
         + ##### 다. 인스턴스의 집합
           ![IMG](/images_files/SQL_027.jpg)
         + ##### 라. 업무프로세스에 의해 이용
         + ##### 마. 속성을 포함
         + ##### 바. 관계의 존재
           > 통계를 위한 엔터티는 관계가 없어도 유효
       + #### 4. 엔터티의 분류
         + ##### 가. 유무(有無)형에 따른 분류
           > * 유형엔터티 : 사원, 물품, 강사 (물리적 형태)
           > * 개념엔터티 : 조직, 보험상품 (물리적 형태 없는 개념적 정보)
           > * 사건엔터티 : 주문, 청구, 미납 (업무에 따라 발생. 발생량 많음)
         + ##### 나. 발생시점(發生時點)에 따른 분류
           + ###### 1) 기본엔터티
             > 독립적 생성 가능. 타 엔터티의 부모역할.
             > * 사원, 부서, 고객, 상품, 자재
           + ###### 2) 중심엔터티
             > * 계약, 사고, 예금원장, 청구, 주문, 매출
           + ###### 3) 행위엔터티
             > 두 개 이상의 부모엔터티로부터 발생. 자주 변경.
             >  * 주문목록, 사원변경이력
         + ##### 다. 엔터티 분류 방법의 예
           ![IMG](/images_files/SQL_031.jpg)
       + #### 5. 엔터티의 명명
         > 현업용어, 약어지양, 단수명사, 유일부여, 생성이름대로 부여
         > * 고객제품 : 고객의 제품인가 고객이 주문한 제품인가?
     + ### 제3절 속성(Attribute)
       + #### 1. 속성 (Attribute)의 개념
         ![IMG](/images_files/SQL_032.jpg)
         > * 업무에서 필요로 한다.
         > * 의미상 더 이상 분리되지 않는다.
         > * 엔터티를 설명하고 인스턴스의 구성요소가 된다.
       + #### 2. 엔터티, 인스턴스와 속성, 속성값에 대한 내용과 표기법
         + ##### 가. 엔터티, 인스턴스, 속성, 속성값의 관계
           > * 한 개의 엔터티는 두 개 이상의 인스턴스의 집합
           > * 한 개의 엔터티는 두 개 이상의 속성을 갖는다.
           > * 한 개의 속성은 한 개의 속성값을 갖는다.
         + ##### 나. 속성의 표기법
       + #### 3. 속성의 특징
         > * 해당 업무에서 필요하고 관리하고자 하는 정보
         > * 정규화 이론에 근간하여 정해진 주식별자에 함수적 종속성
         > * 하나의 속성에는 한 개의 값. 여러 개의 값이 있는 다중값일 경우 별도의 엔터티를 이용하여 분리
       + #### 4. 속성의 분류
         + ##### 가. 속성의 특성에 따른 분류
           + ###### 1) 기본속성
           + ###### 2) 설계속성
           + ###### 3) 파생속성
           ![IMG](/images_files/SQL_035.jpg)
         + ##### 나. 엔터티 구성방식에 따른 분류
           > * 엔터티를 식별 : PK(Primary Key)속성 (사원번호)
           > * 다른 엔터티와의 관계에서 포함된 속성 :  FK(Foreign Key)속성 (부서코드)
           > * 엔터티에 포함되어 있고 PK, FK에 포함되지 않은 속성 : 일반속성 (사원명, 주소)
           > ***
           > 세부 의미를 쪼갤수 있는가 : 복합속성(주소 시구동), 단순속성(나이,성별)
           > ***
           > 속성값의 단복수에따라 : 단일값속성(주민번호), 다중값속성(전화번호)
           > 다중값 속성은 별도 엔터티 만들어 관계로 연결해야함.
       + #### 5. 도메인(Domain)
         > 데이터타입, 크기, 제약사항 (ex.길이가 20자리)
       + #### 6. 속성의 명명(Naming)
         ![IMG](/images_files/SQL_037.jpg)
     + ### 제4절 관계(Relationship)
       + #### 1. 관계의 개념
         + ##### 가. 관계의 정의
         + ##### 나. 관계의 패어링
       + #### 2. 관계의 분류
       + #### 3. 관계의 표기법
         + ##### 가. 관계명(Membership)
         + ##### 나. 관계차수(Degree/Cardinality)
           + ###### 1) 1:1 관계를 표시하는 방법
           + ###### 2) 1:M 관계를 표시하는 방법
           + ###### 3) M:M 관계를 표시하는 방법
         + ##### 다. 관계선택사양(Optionality)
       + #### 4. 관계의 정의 및 읽는 방법
         + ##### 가. 관계 체크사항
         + ##### 나. 관계 읽기
           ![IMG](/images_files/SQL_047.jpg)
     + ### 제5절 식별자
       + #### 1. 식별자(Identifiers) 개념
         > 엔터티에 구성된 속성 중 대표할 수 있는 속성
         > 하나의 엔터티는 반드시 하나의 유일한 식별자가 존재해야 한다.
         > 식별자:논리 데이터 모델링, 키:물리 데이터 모델링 단계에서 사용한다.
       + #### 2. 식별자의 특징
         ![IMG](/images_files/SQL_049.jpg)
       + #### 3. 식별자 분류 및 표기법
         + ##### 가. 식별자 분류
           ![IMG](/images_files/SQL_051.jpg)
         + ##### 나. 식별자 표기법
           ![IMG](/images_files/SQL_052.jpg)
       + #### 4. 주식별자 도출기준
         + ##### 가. 해당 업무에서 자주 이용되는 속성을 주식별자로 지정하도록 함
         + ##### 나. 명칭, 내역 등과 같이 이름으로 기술되는 것은 피함
           > 부서이름(x), 부서코드(o)
         + ##### 다. 속성의 수가 많아지지 않도록 함
           > 인조식별자 도입
       + #### 5. 식별자관계와 비식별자관계에 따른 식별자
         + ##### 가. 식별자관계와 비식별자 관계의 결정
           > 부모 엔터티의 속성(외부식별자)을 주식별자로 쓸것인가 연결속성으로만 쓸것인가
         + ##### 나. 식별자관계
           > 주식별자로 사용. 1:1, 1:M관계
         + ##### 다. 비식별자관계
           > 1. 부모없이 생성가능.
           > 2. 데이터 생명주기 다름(부모가 먼저 소멸 가능.)
           > 3. 여러개의 엔터티가 통합되었을때 각각의 별도 관계(방문,인터넷,전화접수)
           > 4. 주식별자도 가능하나 별도 구성이 더 유리(계약번호,계약사원번호)
         + ##### 라. 식별자 관계로만 설정할 경우의 문제점
           > 하위테이블과 연결시 식별자수 많아짐. 쿼리 복잡
         + ##### 마. 비식별자 관계로만 설정할 경우의 문제점
           > 부모엔터티까지 찾아가서 데이터를 찾아야 하는 문제.
         + ##### 바. 식별자관계와 비식별자관계 모델링
           + ###### 1) 비식별자관계 선택 프로세스
             ![IMG](/images_files/SQL_069.jpg)
           + ###### 2) 식별자와 비식별자관계 비교
             ![IMG](/images_files/SQL_070.jpg)
           + ###### 3) 식별자와 비식별자를 적용한 데이터 모델

   + ## 제2장 데이터 모델과 SQL
     + ### 제1절 정규화
       + #### 1. 제1정규형 : 모든 속성은 반드시 하나의 값을 가져야 한다
       + #### 2. 제2정규형 : 엔터티의 일반속성은 주식별자 전체에 종속적이어야 한다
       + #### 3. 제3정규형 : 엔터티의 일반속성 간에는 서로 종속적이지 않는다
       + #### 4. 반정규화와 성능
         + ##### 가. 반정규화를 적용한 모델에서 성능이 향상될 수 있는 경우
         + ##### 나. 반정규화를 적용한 모델에서 성능이 저하될 수 있는 경우
     + ### 제2절 관계와 조인의 이해
       + #### 1. 조인
       + #### 2. 계층형 데이터 모델
       + #### 3. 상호배타적 관계
     + ### 제3절 모델이 표현하는 트랜잭션의 이해
     + ### 제4절 Null 속성의 이해
       + #### 1. Null 값의 연산은 언제나 Null이다
       + #### 2. 집계함수는 Null 값을 제외하고 처리한다
     + ### 제5절 본질식별자 vs. 인조식별자
       + #### 1. 중복 데이터로 인한 품질 문제
       + #### 2. 불필요한 인덱스 생성

* # 과목 Ⅱ. SQL 기본과 활용
   + ## 제1장 SQL 기본
     + ### 제1절 관계형 데이터베이스 개요
       + #### 1. 데이터베이스
       + #### 2. SQL(Structured Query Language)
       + #### 3. STANDARD SQL 개요
         + ##### 가. 일반 집합 연산자
           ![IMG](/images_files/SQL_200.jpg)
         + ##### 나. 순수 관계 연산자
           ![IMG](/images_files/SQL_201.jpg)
       + #### 4. 테이블
       + #### 5. ERD(Entity Relationship Diagram)
       + #### 6. 데이터 유형
     + ### 제2절 SELECT 문
       + #### 1. SELECT
       + #### 2. 산술 연산자와 합성 연산자
         > 산술:+-/* , 합성:||
     + ### 제3절 함수
       + #### 1. 내장 함수(BUILT-IN FUNCTION) 개요
         ![IMG](/images_files/SQL_182.jpg)
         > 입력값이 많아도 출력은 하나만. M:1
         > * 사용자 정의 함수
         > * 내장 함수(단일행 함수, 다중행 함수(집계함수,그룹함수,윈도우함수) )
       + #### 2. 문자형 함수
         ![IMG](/images_files/SQL_183.jpg)
       + #### 3. 숫자형 함수
         ![IMG](/images_files/SQL_184.jpg)
         ![IMG](/images_files/SQL_185.jpg)
       + #### 4. 날짜형 함수
         ![IMG](/images_files/SQL_186.jpg)
         ![IMG](/images_files/SQL_187.jpg)
       + #### 5. 변환형 함수
         > 명시적 데이터 유형 변환, 암시적 데이터 유형 변환
         > TO_NUMBER, TO_CHAT, TO_DATE
       + #### 6. CASE 표현
       + #### 7. NULL 관련 함수
         + ##### 가. NVL/ISNULL 함수
         + ##### 나. NULL과 공집합
           > 공집합일경우 NVL 미작동. 집계함수와 스칼라 서브쿼리는 공집합이 아닌 NULL 리턴
         + ##### 다. NULLIF
         + ##### 라. 기타 NULL 관련 함수 (COALESCE)
           > 최초 NULL이 아닌값 리턴. 모두 NULL일때 NULL 리턴
     + ### 제4절 WHERE 절
       + #### 1. WHERE 조건절 개요
       + #### 2. 연산자의 종류
         ![IMG](/images_files/SQL_172.jpg)
         ![IMG](/images_files/SQL_173.jpg)
         > * 괄호로 묶은 연산이 제일 먼저 연산 처리된다.
         > * 연산자들 중에는 부정 연산자(NOT)가 먼저 처리되고,
         > * 비교 연산자(=,>,>=,<,<=), SQL 비교 연산자(BETWEEN a AND b, IN (list), LIKE, IS NULL)가 처리되고,
         > * 논리 연산자 중에서는 AND, OR의 순으로 처리된다.
       + #### 3. 비교 연산자
       + #### 4. SQL 연산자
       + #### 5. 논리 연산자
       + #### 6. 부정 연산자
     + ### 제5절 GROUP BY, HAVING 절
       + #### 1. 집계 함수(Aggregate Function)
       + #### 2. GROUP BY 절
       + #### 3. HAVING 절
       + #### 4. CASE 표현을 활용한 월별 데이터 집계
       + #### 5. 집계 함수와 NULL 처리
     + ### 제6절 ORDER BY 절
       + #### 1. ORDER BY 정렬
         > Oracle에서는 Null값이 가장 큰값. 오름차순 마지막. 이외는 반대
       + #### 2. SELECT 문장 실행 순서
         >```sql
         > ⑤ - SELECT 칼럼 명 [ALIAS명]
         > ① - FROM 테이블명
         > ② - WHERE 조건식
         > ③ - GROUP BY 칼럼(Column) 이나 표현식
         > ④ - HAVING 그룹조건식
         > ⑥ - ORDER BY 칼럼(Column) 이나 표현식;
         >```
         + ① 발췌 대상 테이블을 참조한다. (FROM)
         + ② 발췌 대상 데이터가 아닌 것은 제거한다. (WHERE)
         + ③ 행들을 소그룹화 한다. (GROUP BY)
         + ④ 그룹핑된 값의 조건에 맞는 것만을 출력한다. (HAVING)
         + ⑤ 데이터 값을 출력/계산한다. (SELECT)
         + ⑥ 데이터를 정렬한다. (ORDER BY)
     + ### 제7절 조인
       + #### 1. JOIN 개요
       + #### 2. EQUI JOIN
       + #### 3. Non EQUI JOIN
       + #### 4. 3개 이상 TABLE JOIN
       + #### 5. OUTER JOIN

     + ### 제8절 표준 조인
       + #### 1. FROM 절 JOIN 형태
       + #### 2. INNER JOIN
       + #### 3. NATURAL JOIN
         > 동일한 이름을 갖는 모든 칼럼들에 대해 EQUL JOIN
         > USING, ON, WHERE 절에서 JOIN 조건 정의 불가
       + #### 4. USING 조건절
         > 원하는 컬럼. USING (DEPTNO)
       + #### 5. ON 조건절
         + ##### 가. WHERE 절과의 혼용
         + ##### 나. ON 조건절 + 데이터 검증 조건 추가
         + ##### 다. ON 조건절 예제
         + ##### 라. 다중 테이블 JOIN
       + #### 6. CROSS JOIN
       + #### 7. OUTER JOIN
         + ##### 가. LEFT OUTER JOIN
           > 표기된 좌측 테이블에 해당하는 데이터를 먼저 읽은 후, 나중 표기된 우측 테이블에서 JOIN 대상 데이터를 읽어 온다.
           > OUTER 생략 가능. LEFT JOIN, RIGHT JOIN, FULL JOIN
         + ##### 나. RIGHT OUTER JOIN
         + ##### 다. FULL OUTER JOIN
       + #### 8. INNER vs OUTER vs CROSS JOIN 비교
         ![IMG](/images_files/SQL_203.jpg)

   + ## 제2장 SQL 활용
     + ### 제1절 서브 쿼리
       + #### 1. 단일 행 서브 쿼리
       + #### 2. 다중 행 서브쿼리
         > IN, ALL, ANY, EXISTS
       + #### 3. 다중 칼럼 서브쿼리
         > (COL1, COL2) IN ( SELECT ... )
       + #### 4. 연관 서브쿼리
         > 서브쿼리 내에 메인쿼리 칼럼이 사용
       + #### 5. 그밖에 위치에서 사용하는 서브쿼리
         + ##### 가. SELECT 절에 서브쿼리 사용하기
         + ##### 나. FROM 절에서 서브쿼리 사용하기
           > = 인라인 뷰(Inline View) = 동적 뷰
         + ##### 다. HAVING 절에서 서브쿼리 사용하기
       + #### 6. 뷰(View)
         ![IMG](/images_files/SQL_221.jpg)
     + ### 제2절 집합 연산자
       ![IMG](/images_files/SQL_204.jpg)
     + ### 제3절 그룹 함수
       + #### 1. 데이터 분석 개요
         > * AGGREGATE FUNCTION : COUNT, SUM, AVG, MAX, MIN
         > * GROUP FUNCTION : ROLLUP, CUBE, GROUPING SETS
         > * WINDOW FUNCTION : ANALYTIC FUNCTION, RANK FUNCTION
       + #### 2. ROLLUP 함수
         > GROUP BY ROLLUP (DNAME, JOB)
         > * L1 - GROUP BY 수행시 생성되는 표준 집계 (9건)
         > * L2 - DNAME 별 모든 JOB의 SUBTOTAL (3건)
         > * L3 - GRAND TOTAL (마지막 행, 1건)
         > * GROUP BY DNAME, ROLLUP(JOB) // JOB의 부분합만 출력
         > * GROUPING(DNAME) 그룹핑중이면 1
         > * CASE GROUPING(DNAME) WHEN 1 THEN 'All Departments' ELSE DNAME END
       + #### 3. CUBE 함수
         > * GROUP BY CUBE (DNAME, JOB);
         > * DNAME,JOB,DNAME+JOB,모든값에 대한 각각의 GROUP BY
         > * ROLLUP + JOB GROUP BY
       + #### 4. GROUPING SETS 함수
         > * GROUPING SETS (DNAME, JOB);
         > * DNAME GROUP BY, JOB GROUP BY. 수평적.
     + ### 제4절 윈도우 함수
       + #### 1. WINDOW FUNCTION 개요
         >```sql
         > SELECT WINDOW_FUNCTION (ARGUMENTS) OVER ( 
         >    [PARTITION BY 칼럼] [ORDER BY 절] [WINDOWING 절] 
         > ) FROM 테이블명;
         > 
         > * BETWEEN 사용 타입 
         > ROWS | RANGE BETWEEN 
         > UNBOUNDED PRECEDING | CURRENT ROW | VALUE_EXPR PRECEDING/FOLLOWING
         > AND 
         > UNBOUNDED FOLLOWING | CURRENT ROW | VALUE_EXPR PRECEDING/FOLLOWING
         > * BETWEEN 미사용 타입
         > ROWS | RANGE
         > UNBOUNDED PRECEDING | CURRENT ROW | VALUE_EXPR PRECEDING
         > ```
         > * RANGE UNBOUNDED PRECEDING : 현재 행을 기준으로 파티션 내의 첫 번째 행까지의 범위를 지정한다.
         > * RANGE BETWEEN 50 PRECEDING AND 150 FOLLOWING : 현재 행의 급여값을 기준으로 급여가 -50에서 +150의 범위 내에 포함된 모든 행이 대상이 된다.
         > * ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING : 현재 행을 기준으로 파티션 내에서 앞의 한 건, 현재 행, 뒤의 한 건을 범위로 지정한다.
         > * ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING: 현재 행을 포함해서 파티션 내의 마지막 행까지의 범위를 지정한다.
       + #### 2. 그룹 내 순위 함수
         + ##### 가. RANK 함수
           > 1,2,2,4
         + ##### 나. DENSE_RANK 함수
           > 1,2,2,3
         + ##### 다. ROW_NUMBER 함수
           > 1,2,3,4
       + #### 3. 일반 집계 함수
         + ##### 가. SUM 함수
           > 7699-WARD와 7699-MARTIN의 급여가 같으므로, 같은 ORDER로 취급하여 950+1250+1250=3450의 값이 되었다. 7698-TURNER의 경우 950+1250+1250+1500=4950의 누적합을 가진다.
         + ##### 나. MAX 함수
         + ##### 다. MIN 함수
         + ##### 라. AVG 함수
         + ##### 마. COUNT 함수
       + #### 4. 그룹 내 행 순서 함수
         + ##### 가. FIRST_VALUE 함수
         + ##### 나. LAST_VALUE 함수
         + ##### 다. LAG 함수
           > LAG(SAL, 2, 0) 두행앞의 SAL 가져오고, 값이없는 경우는 0
         + ##### 라. LEAD 함수
       + #### 5. 그룹 내 비율 함수
         + ##### 가. RATIO_TO_REPORT 함수
           > 전체합을 1로 놓고 현재값의 백분율. 모두 더하면 1이 된다.
         + ##### 나. PERCENT_RANK 함수
           > 빠른순서0,늦은순서1 : 0,0,0.5,0.75,1
         + ##### 다. CUME_DIST 함수
           > 현재행보다 작거나 같은 누적 : 0.33,0.66,1.00
         + ##### 라. NTILE 함수
           > N등분 구역 리턴. 14건일때 NTILE(4) : 4,4,3,3
     + ### 제5절 Top N 쿼리
       + #### 1. ROWNUM 슈도 칼럼
       + #### 2. TOP 절
       + #### 3. ROW LIMITING 절
     + ### 제6절 계층형 질의와 셀프 조인
       + #### 1. 개요
       + #### 2. 셀프 조인
       + #### 3. 계층형 질의
         + ##### 가. Oracle 계층형 질의
           > ```sql
           > SELECT LEVEL, LPAD(' ', 4 * (LEVEL -1)) || 사원 사원
           >      , 관리자, CONNECT_BY_ISLEAF ISLEAF
           >   FROM 사원
           >  START WITH 관리자 IS NULL
           > CONNECT BY PRIOR 사원 = 관리자;
           > ```
           > * START WITH : 계층 구조 전개의 시작 위치 지정. 루트 데이터 지정
           > * CONNECT BY : 자식 데이터 지정
           > * PRIOR : CONNECT BY절에 사용되며, 현재 읽은 칼럼을 지정한다. PRIOR 자식 = 부모 형태를 사용하면 계층구조에서 자식 데이터에서 부모 데이터(자식 → 부모) 방향으로 전개하는 순방향 전개를 한다. 그리고 PRIOR 부모 = 자식 형태를 사용하면 반대로 부모 데이터에서 자식 데이터(부모 → 자식) 방향으로 전개하는 역방향 전개를 한다.
           > * NOCYCLE : 데이터를 전개하면서 이미 나타났던 동일한 데이터가 전개 중에 다시 나타난다면 이것을 가리켜 사이클(Cycle)이 형성되었다라고 말한다. 사이클이 발생한 데이터는 런타임 오류가 발생한다. 그렇지만 NOCYCLE를 추가하면 사이클이 발생한 이후의 데이터는 전개하지 않는다.
           > * ORDER SIBLINGS BY : 형제 노드(동일 LEVEL) 사이에서 정렬을 수행한다.
           > * WHERE : 모든 전개를 수행한 후에 지정된 조건을 만족하는 데이터만 추출한다.(필터링)
           ![IMG](/images_files/SQL_208.jpg)
           ![IMG](/images_files/SQL_211.jpg)
         + ##### 나. SQL Server 계층형 질의
           > WITH TA AS ( 앵커 멤버(Anchor Member) UNION ALL 재귀 멤버(Recursive Member))
     + ### 제7절 PIVOT 절과 UNPIVOT 절
       + #### 1. 개요
       + #### 2. PIVOT 절
       + #### 2. UNPIVOT 절
     + ### 제8절 정규 표현식
       + #### 1. 개요
       + #### 2. 기본 문법
         + ##### 가. POSIX 연산자
         + ##### 나. PERL 정규 표현식 연산자
       + #### 3. 정규 표현식 조건과 함수
         + ##### 가. REGEXP_LIKE 조건
         + ##### 나. REGEXP_REPLACE 함수
         + ##### 다. REGEXP_SUBSTR 함수
         + ##### 라. REGEXP_INSTR 함수
         + ##### 마. REGEXP_COUNT 함수
   + ## 제3장 관리 구문
     + ### 제1절 DML(Data Manipulation Language)
       + #### 1. INSERT
         + ##### 가. 단일 행 INSERT 문
         + ##### 나. 서브 쿼리를 이용한 다중 행 INSERT 문
       + #### 2. UPDATE
       + #### 3. DELETE
       + #### 4. MERGE
     + ### 제2절 TCL(Transaction Control Language)
       + #### 1. 트랜잭션 개요
         > ![IMG](/images_files/SQL_170.jpg)
       + #### 2. COMMIT
       + #### 3. ROLLBACK
       + #### 4. SAVEPOINT
         > ```sql
         > --Oracle
         > SAVEPOINT SVPT1; -- 저장점 생성
         > ROLLBACK TO SVPT1; -- 저장점까지 롤백
         > --SQL Server
         > SAVE TRANSACTION SVTR1;
         > ROLLBACK TRANSACTION SVTR1;
         > ```
     + ### 제3절 DDL
       + #### 1. CREATE TABLE
         + ##### 가. 테이블과 칼럼 정의
         + ##### 나. CREATE TABLE
         + ##### 다. 제약조건(CONSTRAINT)
         + ##### 라. 생성된 테이블 구조 확인
           > DESCRIBE 테이블명; DESC 테이블명; sp_help 'dbo.테이블명'
         + ##### 마. SELECT 문장을 통한 테이블 생성 사례
       + #### 2. ALTER TABLE
         + ##### 가. ADD COLUMN
           > ```sql
           > ALTER TABLE PLAYER ADD (ADDRESS VARCHAR2(80));
           > ```
         + ##### 나. DROP COLUMN
           > ```sql
           > ALTER TABLE PLAYER DROP COLUMN ADDRESS;
           > ```
         + ##### 다. MODIFY COLUMN
           > 해당 칼럼의 크기를 늘릴 수는 있지만 줄이지는 못한다.
           > 해당 칼럼이 NULL 값만 가지고 있거나 테이블에 아무 행도 없으면 칼럼의 폭을 줄일 수 있다.
           > 해당 칼럼이 NULL 값만을 가지고 있으면 데이터 유형을 변경할 수 있다.
           > 해당 칼럼의 DEFAULT 값을 바꾸면 변경 작업 이후 발생하는 행 삽입에만 영향을 미치게 된다.
           > 해당 칼럼에 NULL 값이 없을 경우에만 NOT NULL 제약조건을 추가할 수 있다.
           > ```sql
           > ALTER TABLE TEAM_TEMP MODIFY (
           >     ORIG_YYYY VARCHAR2(8) DEFAULT '20020129' NOT NULL
           > );
           > ***
           > ALTER TABLE PLAYER RENAME COLUMN PLAYER_ID TO TEMP_ID; -- Oracle
           > sp_rename 'dbo.TEAM_TEMP.TEAM_ID', 'TEAM_TEMP_ID', 'COLUMN'; -- SQLServer
           > ```
         + ##### 라. DROP CONSTRAINT
           > ```sql
           > ALTER TABLE PLAYER DROP CONSTRAINT PLAYER_FK;
           > ```
         + ##### 마. ADD CONSTRAINT
           > ```sql
           > ALTER TABLE PLAYER ADD 
           > CONSTRAINT PLAYER_FK FOREIGN KEY (TEAM_ID) REFERENCES TEAM(TEAM_ID);
           > ***
           > DROP TABLE TEAM;
           > ERROR: 외래 키에 의해 참조되는 고유/기본 키가 테이블에 있다.
           > ```
       + #### 3. RENAME TABLE
         >```sql
         > RENAME TEAM TO TEAM_BACKUP;
         > sp_rename 'dbo.TEAM','TEAM_BACKUP';
         > ```
       + #### 4. DROP TABLE
       + #### 5. TRUNCATE TABLE
     + ### 제4절 DCL(Data Control Languge)
       + #### 1. DCL 개요
         > * DDL : 테이블 생성과 조작에 관련된 명령어
         > * DML : 데이터를 조작하기 위한 명령어
         > * TCL : TRANSACTION을 제어하기 위한 명령어
         > * DCL : 유저를 생성하고 권한을 제어할 수 있는 명령어
       + #### 2. 유저와 권한
         + ##### 가. 유저 생성과 시스템 권한 부여
           > ```sql
           > GRANT CREATE USER TO SCOTT;
           > CREATE USER PJS IDENTIFIED BY KOREA7;
           > ```
         + ##### 나. OBJECT에 대한 권한 부여
           > ```sql
           > GRANT SELECT ON MENU TO SCOTT;
           > ```
       + #### 3. Role을 이용한 권한 부여
         > ```sql
         > REVOKE CREATE SESSION, CREATE TABLE FROM JISUNG;
         > 권한이 취소되었다.
         > 
         > -- CASCADE 옵션을 주면 해당 유저가 생성한 오브젝트를 먼저 삭제한 후 유저를 삭제한다.
         > DROP USER JISUNG CASCADE;
         > ```
* # 과목 Ⅲ. SQL 고급 활용 및 튜닝
   + ## 제1장 SQL 수행 구조
     + ### 제1절 데이터베이스 아키텍처
       + #### 1. 데이터베이스 구조
         + ##### 가. Oracle 구조
           > * SGA 공유 메모리 영역과 이를 액세스하는 프로세스 집합을 합쳐서 인스턴스(Instance)라고 부른다.
           > * 하나의 인스턴스가 하나의 데이터베이스만 액세스
           > * RAC(Real Application Cluster) 환경에서는 여러 인스턴스가 하나의 데이터베이스를 액세스할 수 있다.
           > * 하나의 인스턴스가 여러 데이터베이스를 액세스할 수는 없다.
           ![IMG](/images_files/SQL_260.jpg)
         + ##### 나. SQL Server 구조
           > * 하나의 인스턴스 당 최고 32,767개의 데이터베이스를 정의해 사용할 수 있다.
           > * master, model, msdb, tempdb 등의 시스템 데이터베이스가 만들어지며, 여기에 사용자 데이터베이스를 추가로 생성하는 구조
           > * 데이터베이스 하나를 만들 때마다 주(Primary 또는 Main) 데이터 파일(.mdf)과 트랜잭션 로그 파일(.ldf)이 하나씩 생성.
           > * 저장할 데이터가 많으면 보조(Non-Primary) 데이터 파일을 추가(.ndf)
           ![IMG](/images_files/SQL_261.jpg)
       + #### 2. 프로세스
         + ##### 가. 서버 프로세스(Server Processes)
           > * SQL을 파싱하고 필요하면 최적화를 수행
           > * 커서를 열어 SQL을 실행. 블록을 읽고 정렬해서 클라이언트가 요청한 결과집합 생성. 네트워크를 통해 전송
           + ###### 1) 전용 서버 방식
             > * 처음 연결요청을 받는 리스너가 서버 프로세스(Window 환경에서는 쓰레드)를 생성
             > * 사용자 프로세스를 위해 전용(Dedicated) 서비스를 제공
             > * 전용 서버 방식을 사용하는 OLTP성 애플리케이션에선 Connection Pooling 기법 필수
             > * (ex. 50개의 서버 프로세스와 연결된 50개의 사용자 프로세스를 공유해서 반복 재사용)
           + ###### 2) 공유 서버 방식
             > * 하나의 서버 프로세스를 여러 사용자 세션이 공유(Connection Pooling 기법을 DBMS 내부에 구현)
             > * 미리 여러 개의 서버 프로세스를 띄어 놓고 이를 공유해서 반복 재사용
             > * 사용자 프로세스는 서버 프로세스와 직접 통신하지 않고 Dispatcher 프로세스를 거친다.
             > * 사용자 명령이 Dispatcher에게 전달되면 Dispatcher는 이를 SGA에 있는 요청 큐(Request Queue)에 등록
             > * 이후 가장 먼저 가용해진 서버 프로세스가 요청 큐에 있는 사용자 명령을 꺼내서 처리하고, 그 결과를 응답 큐(Response Queue)에 등록
             > * 응답 큐를 모니터링하던 Dispatcher가 응답 결과를 발견하면 사용자 프로세스에게 전송
         + ##### 나. 백그라운드 프로세스(Background Processes)
           ![IMG](/images_files/SQL_264.jpg)
       + #### 3. 데이터 저장 구조
         + ##### 가. 데이터 파일
           ![IMG](/images_files/SQL_265.jpg)
           + ###### 1) 블록(=페이지)
             > * 데이터 읽고 쓰는 단위. 논리적으로 인접
             > * Oracle:2KB,4KB,8KB,16KB,32KB,64KB / SQL Server:8KB 
           + ###### 2) 익스텐트
             > * 테이블 스페이스로부터 공간을 할당하는 단위. 서로 인접하지 않는다.
             > * 블록8KB. 익스텐트64KB 정의했다면, 공간 부족시 테이블 스페이스로부터 8개의 연속된 블록을 찾아(찾지 못하면 새로 생성) 세그먼트에 할당
             > * Oracle은 한 익스텐트에 속한 모든 블록을 단일 오브젝트가 사용하지만, SQL Server에서는 2개 이상 오브젝트가 나누어 사용할 수도 있다. SQL Server는 다음 2가지 타입의 익스텐트를 사용한다.
             >   * 균일(Uniform) 익스텐트 : 64KB 이상의 공간을 필요로 하는 테이블이나 인덱스를 위해 사용되며, 8개 페이지 단위로 할당된 익스텐트를 단일 오브젝트가 모두 사용
             >   * 혼합(Mixed) 익스텐트 : 한 익스텐트에 할당된 8개 페이지를 여러 오브젝트가 나누어 사용하는 형태다. 모든 테이블이 처음에는 혼합 익스텐트로 시작하지만 64KB를 넘으면서 2번째부터 균일 익스텐트를 사용
           + ###### 3) 세그먼트
             > * 테이블, 인덱스, Undo처럼 저장공간을 필요로 하는 데이터베이스 오브젝트
             > * 저장공간을 필요로 한다는 것은 한 개 이상의 익스텐트를 사용함을 뜻한다. 
             > * 테이블 생성시, 내부적으로 테이블 세그먼트가 생성(1:1)
             > * 인덱스 생성시, 내부적으로 인덱스 세그먼트가 생성(1:1)
             > * 파티션 생성시, 내부적으로 파티션 세그먼트가 생성(1:M)(디스크 경합을 줄이고 I/O 분산 효과)
           + ###### 4) 테이블스페이스
             > 여러 데이터 파일로 구성
         + ##### 나. 임시 데이터 파일
           > * 대량의 정렬, 해시 작업 중 메모리 부족시 중간 결과집합을 저장하는 용도  
           > * 임시 저장 후 자동 삭제. Redo 정보를 생성하지 않기 때문에 복구불가  
           > * Oracle : 임시 테이블 스페이스를 여러 개 생성해 두고, 사용자마다 별도의 임시 테이블 스페이스를 지정 가능  
           > * SQL Server : 단 하나의 tempdb 데이터베이스를 사용. 전역 리소스로서 시스템에 연결된 모든 사용자의 임시 데이터 저장  
         + ##### 다. 로그 파일  
           > * DB 버퍼 캐시에 가해지는 모든 변경사항을 기록하는 파일 : Oracle:Redo로그 / SQL Server:트랜잭션 로그
           > * 로그 파일에 Append 방식으로 빠르게 기록 후 버퍼 블록과 데이터 파일 간 동기화는 적절한 수단(DBWR, Checkpoint)을 이용해 배치(Batch) 방식으로 일괄 처리
           > * Fast Commit 메커니즘 : 사용자의 갱신내용이 메모리상의 버퍼 블록에만 기록된 채 아직 디스크에 기록되지 않았더라도 Redo 로그를 믿고 빠르게 커밋을 완료(인스턴스 장애가 발생하더라도 로그 파일을 이용해 언제든 복구 가능)
           > * Online Redo 로그(Oracle)<br>
           >   * 캐시 복구 : 마지막 체크포인트 이후부터 사고 발생 직전까지 수행되었던 트랜잭션들을 Redo 로그를 이용해 재현<br>
           >   * 최소 두 개 이상의 파일로 구성. 현재 사용 중인 파일이 꽉 차면 다음 파일로 로그 스위칭(log switching)이 발생하며, 계속 로그를 써 나가다가 모든 파일이 꽉 차면 다시 첫 번째 파일부터 재사용하는 라운드 로빈(round-robin) 방식을 사용<br>
           >  * 트랜잭션 로그(SQL Server)  
           >   * Online Redo 로그와 대응. 데이터베이스마다 트랜잭션 로그 파일이 하나씩 생기며, 확장자는 ldf이다.  
           >   * 내부적으로 '가상 로그 파일이라 불리는 더 작은 단위의 세그먼트로 나뉨. 이 가상 로그 파일의 개수가 너무 많아지지 않도록 주의  
           >   * (ex. 로그 파일을 넉넉한 크기로 만들어 자동 증가가 발생하지 않도록 하거나, 증가하는 단위를 크게 지정하는 등)  
           >  * Archived(=Offline) Redo 로그  
           >    * Oracle에서 Online Redo 로그가 재사용되기 전에 다른 위치로 백업해 둔 파일.  
           >    * 디스크가 깨지는 등 물리적인 저장 매체에 문제가 생겼을 때 복구용.  
       + #### 4. 메모리 구조
         > * 시스템 공유 메모리 영역
         >   * 여러 프로세스(또는 쓰레드)가 동시에 액세스할 수 있는 메모리 영역
         >   * Oracle : System Global Area(SGA) / SQL Server : Memory Pool
         >   * DB 버퍼 캐시, 공유 풀, 로그 버퍼. (Large 풀(Large Pool), 자바 풀(Java Pool), 시스템 구조와 제어 구조를 캐싱하는 영역)
         >   * 래치(Latch), 버퍼 
         , 라이브러리 캐시 Lock/Pin 같은 액세스 직렬화 메커니즘이 사용
         > * 프로세스 전용 메모리 영역
         >   * Oracle:서버 프로세스 자신만의 전용 메모리 영역(Process Global Area(PGA)) 
         >   * SQL Server는 프로세스 전용 메모리 영역을 갖지 않는다(부모 프로세스의 메모리 영역을 사용).
         >   * 데이터를 정렬하고 세션과 커서에 관한 상태 정보를 저장하는 용도로 사용
         + ##### 가. DB 버퍼 캐시(DB Buffer Cache)
           + ###### 1) 버퍼 블록의 상태
             > Free 버퍼, Dirty 버퍼, Pinned 버퍼
           + ###### 2) LRU 알고리즘
             > least recently used. 액세스 빈도가 낮은 쪽(LRU end) 데이터 블록부터 밀어내는 방식
         + ##### 나. 공유 풀(Shared Pool)
           > (=SQL Server : Procedure Cache)
           > * 딕셔너리 캐시
           >   * 데이터베이스 딕셔너리(Dictionary) : 테이블, 인덱스, 테이블 스페이스, 데이터 파일, 세그먼트, 익스텐트, 사용자, 제약에 관한 메타 정보 저장. 
           >   * 딕셔너리 캐시 : 딕셔너리 정보를 캐싱하는 메모리 영역
           >   * ex. 입력한 주문 데이터는 데이터 파일에 저장됐다가 버퍼 캐시를 경유해 읽히지만, 테이블 메타 정보는 딕셔너리에 저장됐다가 딕셔너리 캐시를 경유해 읽힌다.
           > * 라이브러리 캐시
           >   * 사용자가 수행한 SQL문과 실행계획, 저장 프로시저를 저장
         + ##### 다. 로그 버퍼(Log Buffer)
           > * Redo 로그 버퍼 > LGWR 프로세스가 Redo 로그 파일에 기록(Log Force at commit) > DB 버퍼 캐시
         + ##### 라. PGA(Process Global Area)
           > * 다른 프로세스와 공유되지 않는 독립적인 메모리 공간. 래치 메커니즘이 필요 없어 SGA 버퍼 캐시 대비 빠름
           > * User Global Area(UGA)
           >   * (=SQL Server:Memory Pool 안에 있는 Connection Context)
           >   * 각 세션을 위한 독립적인 메모리 공간
           >   *  전용 서버 방식 : PGA에 할당 
           >   *  공유 서버 방식 : SGA에 할당(Large Pool이 설정됐을 때는 Large Pool에, 그렇지 않을 때는 Shared Pool에 할당)
           > * Call Global Area(CGA)
           >   * Call이 진행되는 동안에만 필요한 데이터 캐시(다음 Call까지 계속 참조되어야 하는 정보는 UGA에 캐시)
           >   * Parse Call, Execute Call, Fetch Call 마다 매번 할당.
           >   * Call이 진행되는 동안 Recursive Call이 발생하면 그 안에서도 Parse, Execute, Fetch 단계별로 추가로 할당
           >   * Call이 끝나면 PGA로 반환
           > * Sort Area
           >   * (=SQL Server:Memory Pool)
           >   * 소트 오퍼레이션이 진행되는 동안 공간이 부족해질 때마다 청크(Chunk) 단위로 조금씩 할당
     + ### 제2절 SQL 처리 과정
       + #### 1. 구조적, 집합적, 선언적 질의 언어
       + #### 2. SQL 처리 과정
         ![IMG](/images_files/SQL_286.jpg)
         ![IMG](/images_files/SQL_287.jpg)
       + #### 3. SQL 옵티마이저
         > 1. 사용자로부터 전달받은 쿼리를 수행하는 데 후보군이 될만한 실행계획 탐색
         > 2. 데이터 딕셔너리(Data Dictionary)에 미리 수집해 둔 오브젝트 통계 및 시스템 통계정보를 이용해 각 실행계획의 예상비용 산정
         > 3. 최저 비용을 나타내는 실행계획 선택
       + #### 4. 실행계획과 비용
       + #### 5. 옵티마이저 힌트
         + ##### 가. Oracle 힌트
           + ###### 1) 힌트 기술 방법
             >```sql
             > /*+ LEADING(e2 e1) USE_NL(e1) INDEX(e1 emp_emp_id_pk) USE_MERGE(j) FULL(j) */
             > /*+ index(e emp_ename_idx) */
             > /*+ LEADING(e2 e1) USE_NL(e1) INDEX(e1 (employee_id)) */
             >```
           + ###### 2) 힌트가 무시되는 경우
         + ##### 나. SQL Server 힌트
         ![img](/images_files/SQL_294.jpg)
     + ### 제3절 데이터베이스 I/O 메커니즘
       + #### 1. 블록 단위 I/O
         > * 하나의 레코드를 읽더라도 레코드가 속한 블록 전체를 읽는다
       + #### 2. 메모리 I/O vs. 디스크I/O
         + ##### 가. I/O 효율화 튜닝의 중요성
         + ##### 나. 버퍼 캐시 히트율(Buffer Cache Hit Ratio)
           > |call |count |cpu |elapsed |disk |query |current |rows|
           > |------|----|-----|------|----|-----|------|----|
           > |Parse |15 |0.00 |0.08 |0 |0 |0 |0|
           > |Execute |44 |0.03 |0.03 |0 |0 |0 |0|
           > |Fetch |44 |0.01 |0.13 |18 |822 |0 |44|
           > |------|----|-----|------|----|-----|------|----|
           > |total |103 |0.04 |0.25 |18 |822 |0 |44|
           >   
           > * BCHR = (버퍼 캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) × 100
           > * 총 읽은 블록 수 = 822
           > * 버퍼 캐시에서 곧바로 찾은 블록 수 = 822 - 18 = 804
           > * BCHR = (822 - 18) / 822 = 97.8%
         + ##### 다. 네트워크, 파일시스템 캐시가 I/O 효율에 미치는 영향
       + #### 3. Sequential I/O vs. Random I/O
         + ##### 가. Sequential 액세스에 의한 선택 비중 높이기
         + ##### 나. Random 액세스 발생량 줄이기
       + #### 4. Single Block I/O vs. MultiBlock I/O
         > * '인접한 블록'이란, 한 익스텐트(Extent)내에 속한 블록을 말한다. MultiBlock I/O 방식으로 읽더라도 익스텐트 범위를 넘어서까지 읽지는 않는다. 
         > * /*+ index_ffs(t) */
       + #### 5. I/O 효율화 원리
         + ##### 가. 필요한 최소 블록만 읽도록 SQL 작성
         + ##### 나. 최적의 옵티마이징 팩터 제공
         + ##### 다. 필요하다면, 옵티마이저 힌트를 사용해 최적의 액세스 경로로 유도
   + ## 제2장 SQL 분석 도구...?
     + ### 제1절 예상 실행계획
       + #### 1. Oracle
         + ##### 가. Explain Plan
         + ##### 나. AutoTrace
         + ##### 다. DBMS_XPLAN 패키지
       + #### 2. SQL Server
     + ### 제2절 SQL 트레이스
       + #### 1. Oracle
         + ##### 가. SQL 트레이스 수집
         + ##### 나. SQL 트레이스 포맷팅
         + ##### 다. SQL 트레이스 분석
         + ##### 라. DBMS_XPLAN 패키지
       + #### 2. SQL Server
     + ### 제3절 응답 시간 분석
       + #### 1. 대기 이벤트
         + ##### 가. 라이브러리 캐시 부하
           > - 라이브러리 캐시에서 SQL 커서를 찾고 최적화하는 과정에 경합이 발생했음을 나타나는 대기 이벤트
           > * latch: shared pool
           > * latch: library cache
           > - 수행 중인 SQL이 참조하는 오브젝트에 다른 사용자가 DDL 문장을 수행할 때 나타난다.
           > * library cache lock
           > * library cache pin
         + ##### 나. 데이터베이스 Call과 네트워크 부하
           > * SQLNet message from client :  클라이언트로부터 다음 명령이 올 때까지 Idle 상태로 기다릴 때 발생(경합과 무관)
           > * SQLNet message to client, SQLNet more data to client : 클라이언트에게 메시지를 보냈는데 메시지를 잘 받았다는 신호가 정해진 시간보다 늦게 도착
           > * SQLNet more data from client : 클라이언트로부터 더 받을 데이터가 있는데 지연이 발생
         + ##### 다. 디스크 I/O 부하
           > * db file sequential read : Single Block I/O 수행시 대기 이벤트
           > * db file scattered read : Multiblock I/O 수행시 대기 이벤트(Table Full Scan 또는 Index Fast Full Scan)
           > * direct path read
           > * direct path write
           > * direct path write temp
           > * direct path read temp
           > * db file parallel read
         + ##### 라. 버퍼 캐시 경합
           > * latch: cache buffers chains
           > * latch: cache buffers lru chain
           > * buffer busy waits
           > * dfree buffer waits
         + ##### 마. Lock 관련 대기 이벤트
           > * enq: TM - contention
           > * enq: TX - row lock contention
           > * enq: TX - index contention
           > * enq: TX - allocate ITL entry
           > * enq: TX contention
           > * latch free : 특정 자원에 대한 래치를 여러 차례(2,000번 가량) 요청했지만 해당 자원이 계속 사용 중이어서 잠시 대기 상태로 빠질 때마다 발생하는 대기 이벤트
       + #### 2. 응답 시간 분석
         > * Response Time = Service Time + Wait Time = CPU Time + Queue Time
       + #### 3. AWR
         > * Automatic Workload Repository 응답 시간 분석 방법론 지원 Oracle 도구
         > * 동적 성능 뷰 저장, DBMS 건강 상태 체크, 병목원인, 튜닝대상 식별
         > * DMA(Direct Memory Access) : SGA공유메모리 직접 액세스로 빠름.
         + ##### 가. AWR 기본 사용법
         + ##### 나. AWR 리포트 분석
           + ###### 1) 부하 프로필
           + ###### 2) 인스턴스 효율성
           + ###### 3) 공유 풀 통계
           + ###### 4) 최상위 5개 대기 이벤트
   + ## 제3장 인덱스 튜닝
     + ### 제1절 인덱스 기본 원리
       + #### 1. 인덱스 구조
         + ##### 가. 인덱스 기본
           > * Oracle에서 인덱스 구성 칼럼이 모두 null인 레코드는 인덱스에 저장하지 않는다.(인덱스 구성 칼럼 중 하나라도 null 값이 아닌 레코드는 저장)
           > * SQL Server는 인덱스 구성 칼럼이 모두 null인 레코드도 인덱스에 저장한다.
           > * null 값을 Oracle은 맨 뒤에 저장하고, SQL Server는 맨 앞에 저장한다.
         + ##### 나. 인덱스 탐색
       + #### 2. 다양한 인덱스 스캔 방식
         + ##### 가. Index Range Scan
         + ##### 나. Index Full Scan
         + ##### 다. Index Unique Scan
         + ##### 라. Index Skip Scan
           > IN 으로 바꾸면 성능 향상 가능
         + ##### 마. Index Fast Full Scan
           ![IMG](/images_files/SQL_337.jpg)
         + ##### 바. Index Range Scan Descending
       + #### 3. 인덱스 종류
         + ##### 가. B*Tree 인덱스
           + ###### 1) Unbalanced Index
           + ###### 2) Index Skew
             > * 인덱스 엔트리가 왼쪽 또는 오른쪽에 치우치는 현상
           + ###### 3) Index Sparse
             > * 인덱스 블록 전반에 걸쳐 밀도(density)가 떨어지는 현상
           + ###### 4) 인덱스 재생성
             > + 근본적 해결책 아님. 재생성 시간과 부하 등 고려
             > * 인덱스 분할에 의한 경합이 현저히 높을 때
             > * 자주 사용되는 인덱스 스캔 효율을 높이고자 할 때. 특히 NL Join에서 반복 액세스되는 인덱스 높이(height)가 증가했을 때
             > * 대량의 delete 작업을 수행한 이후 다시 레코드가 입력되기까지 오랜 기간이 소요될 때
             > * 총 레코드 수가 일정한데도 인덱스가 계속 커질 때
         + ##### 나. 비트맵 인덱스
           > * Distinct Value 개수가 적을 때 저장 효율 좋음
           > * 인덱스 용량 적어 대용량 테이블에 유용(Distinct Value 많으면 역효과)
           > * 여러 인덱스 혼용 사용 가능
           > * DML 부하 심함(레코드 하나만 변경되더라도 해당 비트맵 범위에 속한 모든 레코드에 Lock이 걸린다.)
           > * 대용량DW, OLAP 환경에 적합
         + ##### 다. 함수기반 인덱스
         + ##### 라. 리버스 키 인덱스
           > * 트랜잭션을 리프 블록 전체에 고르게 분산, =검색만 가능 (범위검색 불가)
         + ##### 마. 클러스터 인덱스
           > * Oracle : 클러스터 테이블 - 인덱스 클러스터, 해시 클러스터
           > * 클러스터 키(여기서는 deptno) 값이 같은 레코드가 한 블록에 모이도록 저장.
           > * 한 블록에 모두 담을 수 없을 때는 새로운 블록을 할당해 클러스터 체인으로 연결
           > * Random 액세스가 값 하나당 한 번씩만 발생(클러스터 체인을 스캔하면서 발생하는 Random 액세스는 제외)
           > * 클러스터에 도달해서는 Sequential 방식으로 스캔하기 때문에 넓은 범위를 검색할 때 유리
           ![IMG](/images_files/SQL_345.jpg)
         + ##### 바. 클러스터형 인덱스/IOT
           > * SQL Server : 클러스터형 인덱스(Clustered Index,=Oracle IOT(Index-Organized Table)), 비클러스터형 인덱스(Non-Clustered Index,=B* Tree 인덱스)
           + ###### 1) 클러스터형 인덱스와 IOT 구조
             > * 구조적으로 B*Tree 인덱스와 같으나, 모든 행 데이터를 인덱스 리프 페이지에 저장(테이블 미생성)
             > * 테이블 당 하나만 생성(한 테이블이 두 개의 정렬 순서를 가질 수 없으므로)
             > * 입력이 느리고 DML부하 심함.
             > * 넓은 범위의 데이터 검색시 유리
             > * 정렬된 리프 페이지를 Sequential 방식으로 스캔(추가적인 테이블 Random 액세스 불필요)
             ![IMG](/images_files/SQL_346.jpg)
           + ###### 2) 클러스터형 인덱스와 IOT 활용
             > * 넓은 범위를 주로 검색하는 테이블
             > * 크기가 작고 NL Join으로 반복 룩업하는 테이블
             > * 칼럼 수가 적고 로우 수가 많은 테이블
             > * 데이터 입력과 조회 패턴이 서로 다른 테이블
           + ###### 3) 2차 인덱스로부터 클러스터형 인덱스와 IOT 참조 방식
             > * SQL Server : 클러스터형 인덱스를 가리키는 2차 인덱스를 비클러스터형 인덱스라고 부른다.
             > * Oracle :  IOT를 가리키는 2차 인덱스를 'Secondary Index'라고 부른다. 
       + #### 4. 인덱스 튜닝 기초
         + ##### 가. 범위 스캔이 불가능하거나 인덱스 사용이 불가능한 경우
         + ##### 나. 인덱스 칼럼의 가공
         + ##### 다. 묵시적 형변환
           > * 숫자vs문자 => 숫자 / 날짜vs문자 => 날짜
     + ### 제2절 테이블 액세스 최소화
       + #### 1. 인덱스 ROWID에 의한 테이블 랜덤 액세스
         + ##### 가. 인덱스 ROWID에 의한 테이블 액세스 구조
         + ##### 나. 클러스터링 팩터
           > * 인덱스 ROWID에 의한 테이블 액세스 비용을 평가
           > * '군집성 계수(= 데이터가 모여 있는 정도)'. 특정 칼럼을 기준으로 같은 값을 갖는 데이터가 서로 모여있는 정도
             ![IMG](/images_files/SQL_350.jpg)
         + ##### 다. 인덱스 손익분기점
           > * 클러스터링 팩터가 나쁘면 손익분기점은 5% 미만에서 결정되며, 심할 때는(BCHR가 매우 안 좋을 때) 1% 미만으로 떨어진다. 반대로 클러스터링 팩터가 아주 좋을 때는 손익분기점이 90% 수준까지 올라가기도 한다
           >  * 인덱스에 의한 액세스가 Full Table Scan보다 더 느리게 만드는 가장 핵심적인 두 가지
           >    + 인덱스 rowid에 의한 테이블 액세스는 Random 액세스 방식, Full Table Scan은 Sequential 액세스 방식
           >    + 디스크 I/O 시, 인덱스 rowid에 의한 테이블 액세스는 Single Block Read 방식을 사용하는 반면, Full Table Scan은 Multiblock Read 방식을 사용
         + ##### 라. 손익분기점 극복하기
           > * 선택도(Selectivity)가 높은 인덱스는 효용가치가 낮다.
           > * SQL Server의 클러스터형 인덱스와 Oracle IOT : 테이블 자체가 인덱스 구조이므로 항상 정렬된 상태를 유지. 인덱스 리프 블록이 곧 데이터 블록이어서 인덱스를 수직 탐색한 다음에 테이블 레코드를 읽기 위한 추가적인 Random 액세스가 불필요
           > * SQL Server의 Include Index : 인덱스 키 외에 미리 지정한 칼럼을 리프 레벨에 함께 저장하는 기능. 테이블 Random 액세스 횟수 감소
           > * Oracle 클러스터 테이블(Clustered Table) : 키 값이 같은 레코드를 같은 블록에 저장. 클러스터 테이블에 대한 클러스터 인덱스를 이용할 때는 테이블 Random 액세스가 키 값별로 한 번씩만 발생. 클러스터에 도달해서는 Sequential 방식으로 스캔하기 때문에 넓은 범위를 읽더라도 비효율이 없다.
           > * 파티셔닝 : 대량 범위검색 조건으로 자주 사용되는 칼럼 기준으로 테이블을 파티셔닝. Full Table Scan 하더라도 일부 파티션만 읽고 멈추도록 할 수 있다. 클러스터는 기준 키 값이 같은 레코드를 블록 단위로 모아 저장하지만 파티셔닝은 세그먼트 단위로 저장하는 점이 다르다.
       + #### 2. 테이블 액세스 최소화 튜닝
         + ##### 가. 인덱스 칼럼 추가
         + ##### 나. Covered Index
           > * 테이블 액세스가 발생하지 않도록 필요한 모든 칼럼을 인덱스에 포함시키는 방법. SQL Server에서는 그런 인덱스를 'Covered 인덱스'라고 부르며, 인덱스만 읽고 처리하는 쿼리를 'Covered 쿼리'라고 부른다.
         + ##### 다. Include Index
           > 인덱스 키 외에 미리 지정한 칼럼(최대 1,023개)을 리프 레벨에 함께 저장하는 기능
         + ##### 라. IOT, 클러스터형 인덱스, 클러스터 테이블 활용
           > * 해시 클러스터 : 해시 함수에서 반환된 값이 같은 데이터를 물리적으로 함께 저장하는 구조
           > * 해시 함수가 인덱스 역할. 별도의 인덱스 구조를 생성하지 않음
           > * = 검색만 가능
         + ##### 마. 수동으로 클러스터링 팩터 높이기
           > * 해당 인덱스 기준으로 테이블을 재생성함으로써 클러스터링 팩터를 인위적으로 좋게 가능
           > * 인덱스가 여러 개인 상황에서 특정 인덱스를 기준으로 테이블을 재정렬하면 다른 인덱스의 클러스터링 팩터가 나빠질 수 있다(인덱스 키 칼럼 간에 상관관계가 높다면 모두 좋아질 수 있음)
           > * 데이터베이스 관리 비용 증가. 가용성에도 영향. 테이블과 인덱스를 Rebuild하는 부담이 적고 그 효과가 확실할 때만 사용.
         + ##### 바. 배치 I/O
           > * ROWID는 고비용(RANDOM ACCESS) 디스크I/O를 모아서 일정량 쌓이면 처리
           > * 모두 버퍼캐시에서 찾는게 아니라면, 인덱스로 인한 정렬 효과 상실(옵티마이저가 SORT ORDER BY 발동)
           > * /*+ batch_table_access_by_rowid */
           > * /*+ no_batch_Table_access_by_rowid */
           > * /*+ index(h 상태변경이력_PK) */ WHERE ROWNUM<=1 -- 지양
     + ### 제3절 인덱스 스캔 효율화
       + #### 1. 인덱스 선행 칼럼이 범위조건일 때의 비효율
       + #### 2. 범위조건을 In-List로 전환
       + #### 3. 범위조건을 2개 이상 사용할 때의 비효율
         > UNION ALL 을 사용하여 인덱스 조건별 쿼리 분리 (ex. and 회사= :com and 지역= :reg and 상품명like :prod || '%')
     + ### 제4절 인덱스 설계
       + #### 1. 결합 인덱스 구성을 위한 기본 공식
         > 조건절 자주 사용. =조건 우선, 소트 오퍼레이션 생략가능추구, 선택도 낮은값
       + #### 2. 추가적인 고려사항
       + #### 3. 인덱스 설계도 작성
   + ## 제4장 조인 튜닝
     + ### 제1절 NL 조인
       + #### 1. 기본 메커니즘
         > ```sql
         > /*+ ordered use_nl(d) */
         > /*+ leading(e) use_nl(d) */
         > ```
       + #### 2. NL Join 수행 과정 분석
       + #### 3. NL Join의 특징
         > * Random 액세스 위주 - 대량의 데이터를 조인할 때 비효율, 메모리 버퍼에서 빠르게 읽더라도 비효율이 존재
         > * 조인을 한 레코드씩 순차적으로 진행. 대용량 집합이더라도 매우 극적인 응답 속도(부분범위처리 가능)
         > * 다른 조인 방식과 비교했을 때 인덱스 구성 전략이 특히 중요
         > * 소량의 데이터를 주로 처리하거나 부분범위처리가 가능한 온라인 트랜잭션 환경에 적합
       + #### TODO 4. NL 조인 확장 메커니즘
         + ##### 가. 전통적인 실행계획
         + ##### 나. 테이블 Prefetch 실행계획
         + ##### 다. 배치 I/O 실행계획
     + ### 제2절 소트 머지 조인
       + #### 1. 기본 메커니즘
       + #### 2. Sort Merge Join의 특징
         > * 테이블별 검색 조건에 의해 전체 일량이 좌우 - Inner 집합
         > * 부분적으로, 부분범위처리가 가능
         > * 스캔 위주 - Inner 테이블을 반복 액세스하지 않으므로 머지 과정에서 Random 액세스가 발생하지 않는다
         > * 각 테이블 검색 조건에 해당하는 대상 집합을 찾을 때 인덱스를 이용한 Random 액세스 방식으로 처리될 수 있고, 이때 발생하는 Random 액세스량이 많다면 Sort Merge Join의 이점이 사라질 수 있다.
         > * 일반 인덱스나 클러스터형 인덱스처럼 미리 정렬된 오브젝트의 경우 정렬작업 생략. 효과적
     + ### 제3절 해시 조인
       + #### 1. 기본 메커니즘
         > * 둘 중 작은 집합(Build Input)을 해시 영역(Hash Area)에 해시 테이블(= 해시 맵)을 생성. 반대쪽 큰 집합(Probe Input)을 읽어 해시 테이블을 탐색하면서 조인하는 방식
         > * Random 액세스 부하가 없고 조인 전 양쪽 집합을 정렬하는 부담도 없다. 
         > * 해시 테이블을 생성하는 비용이 수반
         > * 해시 테이블을 만드는 단계는 부분범위처리 불가, Probe Input을 스캔하는 단계는 부분범위처리 가능.
       + #### 2. Build Input이 가용 메모리 공간을 초과할 때 처리 방식
         > Hash Build를 위한 가용한 메모리 공간에 담길 정도로 Build Input이 충분히 작아야 효과적. In-Memory Hash Join  불가능시 'Grace Hash Join'이라고 알려진 조인 알고리즘 발동. 아래 두단계로 진행
         + ##### 가. 파티션 단계
           > * 조인되는 양쪽 집합(→ 조인 이외 조건절을 만족하는 레코드) 모두 조인 칼럼에 해시 함수를 적용
           > * 반환된 해시 값에 따라 동적으로 파티셔닝. 독립적으로 처리할 수 있는 여러 개의 작은 서브 집합으로 분할함으로써 파티션 짝(pair)을 생성.
           > * 양쪽 집합을 모두 읽어 디스크 상의 Temp 공간에 저장(In-Memory Hash Join보다 성능이 크게 떨어지게 된다.)
         + ##### 나. 조인 단계
           > * 각 파티션 짝(pair)에 대해 하나씩 조인(각각에 대한 Build Input과 Probe Input은 독립적으로 결정된다)
           > * 파티션하기 전 어느 쪽이 작은 테이블이었는지에 상관없이 각 파티션 짝(pair)별로 작은 쪽 파티션을 Build Input으로 선택해 해시 테이블 생성
           > * 해시 테이블이 생성되고 나면 반대 쪽 파티션 로우를 하나씩 읽으면서 해시 테이블을 탐색.
           > * Grace Hash Join은 한마디로, 분할 정복(Divide & Conquer) 방식이라고 말할 수 있다.
           > * Recursive Hash Join(=Nested-loops Hash Join) : Grace Hash Join 중, 디스크에 기록된 파티션 짝(pair)끼리 조인을 수행하려고 '작은 파티션'을 메모리에 로드하는 과정에서 또다시 가용 메모리를 초과하는 경우가 발생. 추가적인 파티셔닝 단계를 거치게 되는데, 이를 'Recursive Hash Join'이라고 한다.
       + #### 3. Build Input 해시 키 값에 중복이 많을 때 발생하는 비효율
         > 해시 알고리즘의 성능은 해시 충돌(collision)을 얼마나 최소화할 수 있느냐에 달렸으며, 이를 방지하려면 그만큼 많은 해시 버킷을 할당해야만 한다. [그림 Ⅲ-4-30]에는 개념적으로 설명하기 위해 하나의 버킷에 여러 키 값이 달리는 구조로 표현하였지만, DBMS는 가능하면 충분히 많은 개수의 버킷을 할당함으로써 버킷 하나당 하나의 키 값만 갖게 하려고 노력한다. 그런데 해시 버킷을 아무리 많이 할당하더라도 해시 테이블에 저장할 키 칼럼에 중복 값이 많다면 하나의 버킷에 많은 엔트리가 달릴 수 밖에 없다. 그러면 해시 버킷을 아무리 빨리 찾더라도 해시 버킷을 스캔하는 단계에서 많은 시간을 허비하기 때문에 탐색 속도가 현저히 저하된다. Build Input의 해시 키 칼럼에는 중복 값이 (거의) 없어야 Hash Join이 빠르게 수행될 수 있음을 이해할 것이다.
         ![IMG](/images_files/SQL_361.jpg)
       + #### 4. Hash Join 사용기준
         > * 한 쪽 테이블이 가용 메모리에 담길 정도로 충분히 작아야 함
         > * Build Input 해시 키 칼럼에 중복 값이 거의 없어야 함
         > * 조인 칼럼에 적당한 인덱스가 없어 NL Join이 비효율적일 때
         > * 조인 칼럼에 인덱스가 있더라도 NL Join 드라이빙 집합에서 Inner 쪽 집합으로의 조인 액세스량이 많아 Random 액세스 부하가 심할 때
         > * Sort Merge Join 하기에는 두 테이블이 너무 커 소트 부하가 심할 때
         > * 수행빈도가 낮고 대용량 테이블을 조인할 때
         > * ①수행 빈도가 낮고 ②쿼리 수행 시간이 오래 걸리는 ③대용량 테이블을 조인할 때(→ 배치 프로그램, DW, OLAP성 쿼리의 특징이기도 함) 주로 사용. OLTP 환경이라고 Hash Join을 쓰지 못할 이유는 없지만 이 세 가지 기준(①~③)을 만족하는지 체크
     + ### 제4절 스칼라 서브쿼리
       + #### 1. Scalar Subquery의 캐싱 효과
       + #### 2. 두 개 이상의 값을 리턴하고 싶을때
       + #### 3. 스칼라 서브 쿼리 Unnesting
         > ```sql
         > /*+ unnest */ -- 서브쿼리를 Unnesting 함으로써 조인방식으로 최적화하도록 유도.
         > /*+ no_unnest */ --  서브쿼리를 그대로 둔 상태에서 필터 방식으로 최적화하도록 유도.
         > ```
     + ### 제5절 고급 조인 기법
       + #### 1. 인라인 뷰 활용
         > 1쪽 집합 단위로 그룹핑해야 한다면 M쪽 집합을 먼저 1쪽 단위로 그룹핑하고 나서 조인하는 것이 유리(조인횟수줄어듬)
       + #### 2. 배타적 관계의 조인
         > ```sql
         > select * from 작업지시 a, 개통신청 b, 장애접수 c
         > where a.방문예정일시 = :방문예정일시 
         > and b.개통신청번호(+) = decode(a.작업구분, '1', a.접수번호) 
         > and c.장애접수번호(+) = decode(a.작업구분, '2', a.접수번호) 
         > ```
         ![IMG](/images_files/SQL_362.jpg)
       + #### 3. 부등호 조인
       + #### 4. Between 조인
         + ##### 가. 선분이력이란?
         + ##### 나. 선분이력 기본 조회 패턴
         + ##### 다. 선분이력 조인
           + ###### 1) 과거,현재,미래의 임의 시점 조회
           + ###### 2) 현재 시점 조회
         + ##### 라. Between 조인
       + #### 5. ROWID 활용
         > ```sql
         > and b.rowid = ( select /*+ index(c 고객별연체이력_idx01) */ rowid from 고객별연체이력c where ...
         > ```
   + ## 제5장 SQL 옵티마이저
     + ### 제1절 SQL 옵티마이징 원리
       + #### 1. 옵티마이저 소개
         + ##### 가. 옵티마이저 종류
           + ###### 1) 규칙기반 옵티마이저
             > * Rule-Based Optimizer(RBO), 휴리스틱(Heuristic) 옵티마이저
           + ###### 2) 비용기반 옵티마이저
             > * Cost-Based Optimizer(CBO)
         + ##### 나. 최적화 목표
           + ###### 1) 전체 처리속도 최적화
             > ```sql
             > alter system set optimizer_mode = all_rows;  
             > /*+ all_rows */
             > ```
           + ###### 2) 최초 응답속도 최적화
             > ```sql
             > /*+ first_rows(10) */
             > where OPTION(fast 10);
             > ```
       + #### 2. 옵티마이저 행동에 영향을 미치는 요소
         + ##### 가. SQL과 연산자 형태
         + ##### 나. 옵티마이징 팩터
           > * 인덱스, IOT, 클러스터링, 파티셔닝, MV
         + ##### 다. DBMS 제약 설정
           > * 개체 무결성, 참조 무결성, 도메인 무결성 등을 위해 DBMS가 제공하는 PK, FK, Check, Not Null 같은 제약 설정 기능
           > * 인덱스 칼럼에 Not Null 제약이 설정돼 있으면 옵티마이저는 전체 개수를 구하는 Count 쿼리에 이 인덱스를 활용
         + ##### 라. 옵티마이저 힌트
         + ##### 마. 통계정보
         + ##### 바. 옵티마이저 관련 파라미터
         + ##### 사. DBMS 버전과 종류
       + #### 3. 옵티마이저의 한계
         + ##### 가. 옵티마이징 팩터의 부족
           > * 적절한 옵티마이징 팩터(효과적으로 구성된 인덱스, IOT, 클러스터링, 파티셔닝 등)를 제공
         + ##### 나. 통계정보의 부정확성
           > * 연봉과 직급 관계. 4직급 1000명, 히스토그램상 연봉>=5000 비중이 10%일때
           > * 부장5000이상 계산:25(1000\*0.25\*0.1). 실제:250(1000\*0.25*1)
         + ##### 다. 바인드 변수 사용 시 균등분포 가정
           > * 조건절에 바인드 변수를 사용하면 옵티마이저가 균등분포를 가정
         + ##### 라. 비현실적인 가정
           > * 구 Oracle : Single Block I/O와 Multiblock I/O의 비용을 같게 평가하거나 데이터 블록의 캐싱 효과도 고려하지 않는 등
         + ##### 마. 규칙에 의존하는 CBO
         + ##### 바. 하드웨어 성능
       + #### 4. 통계정보를 이용한 비용계산 원리
         ![IMG](/images_files/SQL_288.jpg)
         + ##### 가. 선택도
           > * 전체 대상 레코드 중에서 특정 조건에 의해 선택될 것으로 예상되는 레코드 비율
           > * 선택도 = 1 / Distinct Value 개수 = 1 / num_distinct
           > * 선택도 → 카디널리티 → 비용 → 액세스 방식, 조인 순서, 조인 방법 등 결정
           > * 히스토그램이 있으면 그것으로 선택도를 산정하며, 단일 칼럼에 대해서는 비교적 정확한 값을 구한다. 히스토그램이 없거나, 있더라도 조건절에 바인드 변수를 사용하면 옵티마이저는 데이터 분포가 균일하다고 가정한 상태에서 선택도를 구한다
         + ##### 나. 카디널리티
           > * 특정 액세스 단계를 거치고 난 후 출력될 것으로 예상되는 결과 건수
           > * 카디널리티 = 총 로우 수 × 선택도 = num_rows / num_distinct
         + ##### 다. 히스토그램
           > * 미리 저장된 히스토그램 정보가 있으면, 옵티마이저는 그것을 사용해 더 정확하게 카디널리티를 구할 수 있다.
           > * 특히, 분포가 균일하지 않은 칼럼으로 조회할 때 효과를 발휘
           > * 바인드 변수를 사용하면 균등분포 가정. DW, OLAP에서는 상수 조건 유용
            + ###### * 도수분포 히스토그램
              > * 값별로 빈도수(frequency number)를 저장
              > * 칼럼이 가진 값의 수가 적을 때 사용
              > * 각각 하나의 버킷을 할당(값의 수 = 버킷 개수)
              ![IMG](/images_files/SQL_290.jpg)
            + ###### * 높이균형 히스토그램
              > * 칼럼이 가진 값의 수가 아주 많아 각각 하나의 버킷을 할당하기 어려울 때 사용
              > * 하나의 버킷이 여러 개 값을 담당
              > * 빈도 수가 많은 값(popular value)에 대해서는 두 개 이상의 버킷이 할당
              ![IMG](/images_files/SQL_291.jpg)
         + ##### 라. 비용
           > * 쿼리를 수행하는데 소요되는 일량 또는 시간. 예상치.
           > * I/O 비용 모델 : 예상되는 I/O 요청(Call) 횟수만을 평가 / CPU 비용 모델 : 여기에 시간 개념을 더해 비용을 산정
            + ###### * 인덱스를 경유한 테이블 액세스 비용
              > * 디스크 I/O Call 횟수(논리적/물리적으로 읽은 블록 개수가 아닌 I/O Call 횟수)를 의미
              > * 인덱스를 경유한 테이블 액세스 시에는 Single Block I/O 방식이 사용
              > 비용 = blevel -- 인덱스 수직적 탐색 비용  
              >  + (리프 블록 수 × 유효 인덱스 선택도) -- 인덱스 수평적 탐색 비용  
              >  + (클러스터링 팩터 × 유효 테이블 선택도) -- 테이블 Random 액세스 비용  
              ![IMG](/images_files/SQL_293.jpg)
            + ###### Full Scan에 의한 테이블 액세스 비용
              > * 총 블록 수를 Multiblock I/O 단위로 나눈 만큼 I/O Call이 발생
              > * 100블록을 8개씩 나누어 읽는다면 13번의 I/O Call이 발생하고, I/O Call 횟수로써 Full Scan 비용을 추정
     + ### 제2절 SQL 공유 및 재사용
       + #### 1. 소프트 파싱 vs. 하드 파싱
         > * 라이브러리 캐시 : 시스템 공유 메모리에서 SQL과 실행계획이 캐싱되는 영역
         > * SQL을 실행 > SQL 파서(Parser) : 문법적 오류 검사(Syntax 검사) > 의미상 오류(Semantic 검사. ex.존재하지 않거나 권한이 없는 객체를 사용했는지, 또는 존재하지 않는 칼럼을 사용했는지 등) > SQL과 실행계획이 라이브러리 캐시에 캐싱됐는지 확인 > 소프트/하드파싱 분기
         > * 소프트 파싱(Soft Parsing) : SQL과 실행계획을 캐시에서 찾아 곧바로 실행단계로 넘어가는 경우를 말함
         > * 하드 파싱(Hard Parsing) : SQL과 실행계획을 캐시에서 찾지 못해 최적화 과정을 거치고 나서 실행단계로 넘어가는 경우를 말함
         + ##### 가. SQL 공유 및 재사용의 필요성
         + ##### 나. 실행계획 공유 조건
           >  캐시에서 SQL을 찾기 위해 사용되는 키 값이 SQL 문장 그 자체
         + ##### 다. 실행계획을 공유하지 못하는 경우
       + #### 2. 바인드 변수 사용하기
         + ##### 가. 바인드 변수의 중요성
           > * 바인드를 쓰지 말아야 할 경우.
           >   * DW, OLAP 에서 Long Running쿼리. 옵티마이저가 칼럼 히스토그램 활용 유도
           >   * 조건절 칼럼 값(Distinct Value)가 소수일때. 칼럼 히스토그램 활용 유도
         + ##### 나. 바인드 변수 사용 시 주의사항
         + ##### 다. 바인드 변수 부작용을 극복하기 위한 노력
           > * 바인드 변수 Peeking(Parameter Sniffing) 변수 값을 먼저 보고 칼럼 히스토그램 활용
           > * 최초값에 의해 성능이 결정되어 불안
           > ***
           > * 쿼리 바인딩 값에 따라 쿼리 분기  
           > ex.서울,경기/*+FULL(A)*/ UNION ALL 기타지방/*+INDEX(a IDX01)*/
       + #### 3. 애플리케이션 커서 캐싱
         > * 라이브러리 캐시뿐 아니라 문법적,의미적 검사도 캐시처리. 구현 언어마다 다르니 주의  
         > ex. JAVA 묵시적 캐싱 (Statement 를 닫지 않는것과 같은 효과)
         > ```java
         > ((OracleConnection)conn).setStatementCacheSize(1);
         > ((OracleConnection)conn).setImplicitCachingEnabled(true)
         > ```
       + #### 4. Static SQL vs. Dynamic SQL
         + ##### 가. Static SQL
           > 코드사이에 SQL 직접 기술. Embedded SQL. PowerBuilder, PL/SQL 등 일부언어.
         + ##### 나. Dynamic SQL
           > String형 변수에 SQL 담아 실행
         + ##### 다. 바인드 변수의 중요성 재강조
     + ### 제3절 쿼리 변환
       + #### 1. 쿼리변환이란?
         > * 결과가 동일하면 나은성능이 기대되는 형태로 재작성
         > * 휴리스틱(Heuristic) 쿼리 변환 : 결과만 보장된다면 무조건 쿼리 변환을 수행한다. 일종의 규칙 기반(Rule-based) 최적화 기법이라고 할 수 있으며, 경험적으로 (최소한 동일하거나) 항상 더 나은 성능을 보일 것이라는 옵티마이저 개발팀의 판단이 반영된 것이다.
         > * 비용기반(Cost-based) 쿼리 변환 : 변환된 쿼리의 비용이 더 낮을 때만 그것을 사용하고, 그렇지 않을 때는 원본 쿼리 그대로 두고 최적화를 수행한다.
       + #### 2. 서브쿼리 Unnesting
         > * unnest : 서브쿼리를 Unnesting 함으로써 조인방식으로 최적화
         > * no_unnest : 서브쿼리를 그대로 둔 상태에서 필터 방식으로 최적화
       + #### 3. 뷰 Merging
         > /*+ merge */ , /*+ no_merge */
         > * 뷰 Merging 불가
         >   * 집합(set) 연산자(union, union all, intersect, minus)
         >   * connect by절
         >   * ROWNUM pseudo 칼럼
         >   * select-list에 집계 함수(avg, count, max, min, sum) 사용
         >   * 분석 함수(Analytic Function)
       + #### 4. 조건절 Pushing
         + ##### 가. 조건절(Predicate) Pushdown
           > 쿼리 블록 밖에 있는 조건절을 쿼리 블록 안쪽으로 밀어 넣는 것
         + ##### 나. 조건절(Predicate) Pullup
           > 쿼리 블록 안에 있는 조건절을 쿼리 블록 밖으로 내오는 것을 말하며, 그것을 다시 다른 쿼리 블록에 Pushdown 하는 데 사용함
         + ##### 다. 조인 조건(Join Predicate) Pushdown
           > NL Join 수행 중에 드라이빙 테이블에서 읽은 값을 건건이 Inner 쪽(=right side) 뷰 쿼리 블록 안으로 밀어 넣는 것
       + #### 5. 조건절 이행
         > 「(A = B)이고 (B = C)이면 (A = C)이다」
       + #### 6. 불필요한 조인 제거
         > * 1:M 관계인 두 테이블을 조인하는 쿼리문에서 조인문을 제외한 어디에서도 1쪽 테이블을 참조하지 않는다면, 쿼리 수행 시 1쪽 테이블은 읽지 않아도 된다.
         > * '조인 제거(Join Elimination)' 또는 '테이블 제거(Table Elimination)'라고 한다
       + #### 7. OR 조건을 Union으로 변환
         > * WHERE JOB='CLERK' UNION ALL WHERE DEPTNO='20' AND LNNVL(JOB='CLERK')
         > * /*+ use_concat */ (OR-Expansion을 유도), /*+ no_expand */ 
       + #### 8. 기타 쿼리 변환
         + ##### 가. 집합 연산을 조인으로 변환
           > * 안티조인 = NOT EXISTS
           > * sys_op_map_nonnull(job) = sys_op_map_nonnull(e.job) -- 둘다 같은값, 또는 둘다 NULL이면 TRUE
         + ##### 나. 조인 칼럼에 IS NOT NULL 조건 추가
         + ##### 다. 필터 조건 추가
           > between 연산시 시작값이 종료값보다 큰경우 등
         + ##### 라. 조건절 비교 순서
           > A=1,1,1,1,1,.... B=...88,89,90,91,... 일때 B먼저 비교
   + ## 제6장 고급 SQL 튜닝
     + ### 제1절 소트 튜닝
       + #### 1. 소트와 성능
         + ##### 가. 메모리 소트와 디스크 소트
           > ||Oracle|SQL Server|
           > |---|---|---|
           > |메모리 소트 영역|PGA(Private Global Area)|버퍼 캐시|
           > |디스크 소트 영역|Temp Tablespace|tempdb|
         + ##### 나. 소트를 발생시키는 오퍼레이션
           + ###### 1) Sort Aggregate
             > 전체 로우를 대상으로 집계를 수행할 때 나타나며, 실행계획에 ‘sort’라는 표현이 사용됐지만 실제 소트가 발생하진 않는다. SQL Server 실행계획엔 ‘Stream Aggregate’라고 표시된다. (group by 없는 sum,min,max...)
           + ###### 2) Sort Order By
             > 정렬된 결과집합을 얻고자 할 때 나타난다.(order by)
           + ###### 3) Sort Group By
             > Sorting 알고리즘을 사용해 그룹별 집계를 수행할 때 나타난다.(sum,min,max)
           + ###### 4) Sort Unique
             > 선택된 결과집합에서 중복 레코드를 제거(Union, Distinct)
           + ###### 5) Sort Join
             > Sort Merge Join (/*+ ordered use_merge(e) */)
           + ###### 6) Window Sort
             > 윈도우 함수(row_number() over (order by hiredate))
         + ##### 다. 소트 튜닝 요약
           > * 메모리 집약적(Memory-intensive), CPU 집약적(CPU-intensive), 데이터량이 많을 때는 디스크 I/O까지 발생
           > * 부분범위처리를 할 수 없게 만들어 OLTP 환경에서 성능을 떨어뜨리는 주요인
           > * 가급적 소트가 발생하지 않도록 작성, 소트가 불가피하다면 메모리 내에서 수행을 완료할 수 있도록 해야 한다
           >   - 데이터 모델 측면에서의 검토
           >   - 소트가 발생하지 않도록 SQL 작성
           >   - 인덱스를 이용한 소트 연산 대체
           >   - 소트 영역을 적게 사용하도록 SQL 작성
           >   - 소트 영역 크기 조정
       + #### 2. 데이터 모델 측면에서의 검토
       + #### 3. 소트가 발생하지 않도록 SQL 작성
         + ##### 가. Union을 Union All로 대체
         + ##### 나. Distinct를 Exists 서브쿼리로 대체
           > * select distinct 과금연월 을 select 연월 exists() 로 변경
         + ##### 다. 불필요한 Count 연산 제거
           > * 존재 확인을 위한 count라면 exists나 rownum<=1 을 사용
       + #### 4. 인덱스를 이용한 소트 연산 대체
         + ##### 가. Sort Order By 대체
         + ##### 나. Sort Group By 대체
         + ##### 다. 인덱스를 활용한 Min, Max 구하기
           >```sql
           >  INDEX (RANGE SCAN (MIN/MAX)) OF '주문_PK' (INDEX (UNIQUE))
           >```
       + #### 5. 소트 영역을 적게 사용하도록 SQL 작성
         + ##### 가. 소트 완료 후 데이터 가공
           > select lpad(aaa,30) from (select * from order by)
         + ##### 나. Top N 쿼리
           > ```sql
           > select 고객ID, 변경순번, 전화번호, 주소, 자녀수, 직업, 고객등급
           >   from (select 고객ID, 변경순번
           >              , max(변경순번) over (partition by 고객ID) 마지막변경순번
           >              , 전화번호, 주소, 자녀수, 직업, 고객등급
           >           from 고객변경이력)
           >  where 변경순번 = 마지막변경순번
           > 
           > -- 윈도우 함수를 사용할 때도 max() 함수보다 아래와 같이 rank()나 row_number() 함수를 사용하는 것이 유리한데, 이것 역시 Top-N 쿼리 알고리즘이 작동하기 때문이다.
           > 
           > select 고객ID, 변경순번, 전화번호, 주소, 자녀수, 직업, 고객등급
           >   from (select 고객ID, 변경순번
           >              , rank() over (partition by 고객ID order by 변경순번) rnum
           >              , 전화번호, 주소, 자녀수, 직업, 고객등급
           >           from 고객변경이력)
           >  where rnum = 1
           > ```
         + ##### 다. Top N 쿼리를 이용한 효과적인 이력 조회
       + #### 6. 소트 영역 크기 조정
     + ### 제2절 DML 튜닝
       + #### 1. 인덱스 유지 비용
         > * 변경할 인덱스 레코드를 찾아가는 비용, Redo, Undo 생성 비용, Update의 경우 Delete & Insert, 인덱스 정렬을 위한 Undo 레코드 2개씩 기록
         > * 인덱스를 모두 Drop하거나 Unusable 상태로 변경한 다음에 작업하는 것이 빠를 수 있다. 인덱스를 재생성하는 시간까지 포함하더라도.
       + #### 2. Insert 튜닝
         + ##### 가. Oracle Insert 튜닝
           > * Direct Path Insert : IOT(index-organized table)는 정해진 키(Key) 순으로 정렬하면서 값을 입력하는 반면, 일반적인 힙 구조 테이블(heap-organized table)은 순서 없이 Freelist로부터 할당받은 블록에 무작위로 값을 입력한다. Freelist는 HWM(High-Water Mark) 아래쪽에 위치한 블록 중 어느 정도(테이블에 지정한 pctfree와 pctused 파라미터에 의해 결정됨) 빈 공간을 가진 블록 리스트를 관리하는 자료구조다. Freelist에서 할당받은 블록을 버퍼 캐시에서 찾아보고, 없으면 데이터 파일에서 읽어 캐시에 적재한 후에 데이터를 삽입한다. 일반적인 트랜잭션을 처리할 때는 빈 공간부터 찾아 채워 나가는 위 방식이 효율적이다. 하지만, 대량의 데이터를 Bulk로 입력할 때는 매우 비효율적이다. 빈 블록은 얼마 지나지 않아 모두 채워지고 이후부터는 순차적으로 뒤쪽에만 데이터를 쌓게 될 텐데도 건건이 Freelist를 조회하면서 입력하기 때문이다. Freelist를 거치지 않고 HWM 바깥 영역에, 그것도 버퍼 캐시를 거치지 않고 데이터 파일에 곧바로 입력하는 Direct Path Insert 방식을 사용하면 대용량 Insert 속도를 크게 향상시킬 수 있다. 이 방식을 사용할 때 Undo 데이터를 쌓지 않는 점도 속도 향상의 주요인이다. 사용자가 커밋할 때만 HWM를 상향 조정하면 되기 때문에 Undo 데이터가 불필요하다. 아래는 Oracle에서 Direct Path Insert 방식으로 데이터를 입력하는 방법이다.
           >   * insert select 문장에 /*+ append */ 힌트 사용
           >   * 병렬 모드로 insert
           >   * direct 옵션을 지정하고 SQL*Loader(sqlldr)로 데이터를 로드
           >   * CTAS(create table … as select) 문장을 수행
           >   * nologging 모드 Insert
           > ```sql
           > alter table t NOLOGGING;
           > ```
           > * Exclusive 모드 테이블 Lock(트랜잭션 빈번 주간에 사용지양), 장애가 발생했을 때 복구가 불가(백업을 실시)
           > * 배치 프로그램에서 중간 단계의 임시 테이블, DW 시스템에 읽기 전용 데이터 등 재생 가능 OLTP에 적합
         + ##### 나. SQL Server Insert 튜닝
       + #### 3. Update 튜닝
         + ##### 가. Truncate & Insert 방식 사용
           > * 테이블 데이터를 갱신하는 본연의 작업
           > * 인덱스 데이터까지 갱신
           > * 버퍼 캐시에 없는 블록를 디스크에서 읽어 버퍼 캐시에 적재한 후에 갱신
           > * 내부적으로 Redo와 Undo 정보 생성
           > * 블록에 빈 공간이 없으면 새 블록 할당(→ Row Migration 발생)
         + ##### 나. 조인을 내포한 Update 튜닝
           > * /*+ unnest */ /*+ hash_sj */ 
           > * /*+ bypass_ujvc */
           > * merge into
     + ### 제3절 데이터베이스 Call 최소화
       + #### 1. 데이터베이스 Call 종류
         + ##### 가. SQL 커서에 대한 작업 요청에 따른 구분
           + ###### 1) Parse Call
             > SQL 파싱을 요청하는 Call
           + ###### 2) Execute Call
             > SQL 실행을 요청하는 Call
           + ###### 3) Fetch Call
             > SELECT문의 결과 데이터 전송을 요청하는 Call
         + ##### 나. Call 발생 위치에 따른 구분
           + ###### 1) User Call
             > * DBMS 외부로부터 요청되는 Call
           + ###### 2) Recursive Call
             > * DBMS 내부에서 발생하는 Call
             > * SQL 파싱과 최적화 과정에서 발생하는 데이터 딕셔너리 조회, 사용자 정의 함수/프로시저 내에서의 SQL 수
             > * 바인드 변수를 적극적으로 사용해 하드파싱 발생횟수를 줄여야.
       + #### 2. 데이터베이스 Call과 성능
         + ##### 가. One SQL 구현의 중요성
         + ##### 나. 데이터베이스 Call과 시스템 확장성
       + #### 3. Array Processing 활용
       + #### 4. Fetch Call 최소화
         + ##### 가. 부분범위처리 원리
           > * 30,000개 로우를 읽기 위해 Fetch Call이 301번 발생 = ArraySize가 100으로 설정된 상태에서 수행된 쿼리
           > * OLTP 환경에서는 일부만 Fetch 하고 멈춰도 되는 업무가 많다. 부분범위처리
         + ##### 나. ArraySize 조정에 의한 Fetch Call 감소 및 블록 I/O 감소 효과
           > * ArraySize = 3 => Fetch 10회, 블록I/O 12회
           > * ArraySize = 10 => Fetch 3회, 블록I/O 3회
           > * ArraySize = 30 => Fetch 1회, 블록I/O 3회
           ![IMG](/images_files/SQL_270.jpg)
       + #### 5. 페이지 처리 활용
         > * 페이지 단위로, 화면에서 필요한 만큼만 Fetch Call
         > * 페이지 단위로, 화면에서 필요한 만큼만 네트워크를 통해 결과 전송
         > * 인덱스와 부분범위처리 원리를 이용해 각 페이지에 필요한 최소량만 I/O
         > * 데이터를 소량씩 나누어 전송하므로 AP웹 서버 리소스 사용량 최소화
       + #### 6. 분산 쿼리
         > /*+ driving_site(b) */
       + #### 7. 사용자 정의 함수/프로시저의 특징과 성능
         + ##### 가. 사용자 정의 함수/프로시저의 특징
           > * 실행될 때마다 컨텍스트 스위칭(Context Switching)이 발생
           > * 메인 쿼리가 참조하는 사용자 정의 함수에 또 다른 쿼리문이 내장돼 있으면, 내장된 쿼리를 수행될 때마다 Execute Call, Fetch Call이 재귀적 발생(Recursive Call)
         + ##### 나. 사용자 정의 함수/프로시저에 의한 성능 저하 해소 방안
     + ### 제4절 파티셔닝
       + #### 1. 파티션 개요
       + #### 2. 파티션 유형
         + ##### 가. RANGE 파티셔닝
           > 날짜
         + ##### 나. HASH 파티셔닝
           > 고객번호, 주문 일련번호
         + ##### 다. LIST 파티셔닝
           > 지역
         + ##### 라. Composite 파티셔닝
           > partition by range(주문일자) subpartition by hash(고객id) subpartitions 8
       + #### 3. 파티션 Pruning
         + ##### 가. 정적(Static) 파티션 Pruning
           > * 컴파일 시점. 파티션 키 상수조건
         + ##### 나. 동적(Dynamic) 파티션 Pruning
           > * 실행 시점. 파티션 키 바인드. NL Join Inner테이블일때도 동적
       + #### 4. 인덱스 파티셔닝
         + ##### 가. Local 파티션 인덱스 vs. Global 파티션 인덱스
           ![IMG](/images_files/SQL_403.jpg)
           ![IMG](/images_files/SQL_404.jpg)
         + ##### 나. Prefixed 파티션 인덱스 vs. NonPrefixed 파티션 인덱스
           > * Prefixed : 파티션 키 칼럼을 인덱스 키 칼럼 왼쪽 선두에 두는 것
           > * Nonprefixed : 파티션 키 칼럼을 인덱스 키 칼럼 왼쪽 선두에 두지 않는 것. 파티션 키가 인덱스 칼럼에 아예 속하지 않을 때도 여기에 속한다.
           >   + Local Prefixed 파티션 인덱스
           >   + Local NonPrefixed 파티션 인덱스
           >   + Global Prefixed 파티션 인덱스
           >   + Global NonPrefixed 파티션 인덱스 (→ Oracle Not Support)
           >   + 비파티션(NonPartitioned) 인덱스
         + ##### 다. 인덱스 파티셔닝 가이드
           ![IMG](/images_files/SQL_407.jpg)
     + ### 제5절 대용량 배치 프로그램 튜닝
       + #### 1. 배치 프로그램 튜닝 개요
         + ##### 가. 배치 프로그램이란
         + ##### 나. 배치 환경의 변화
         + ##### 다. 성능 개선 목표 설정
         + ##### 라. 배치 프로그램 구현 패턴과 튜닝 방안
       + #### 2. 병렬 처리 활용
         >```sql
         > /*+ full(o) parallel(o, 4) */
         > /*+ index_ffs(o, 주문_idx)) parallel_index(o, 주문_idx, 4) */
         >```
         + ##### 가. Query Coordinator와 병렬 서버 프로세스
           >```sql
           >/*+ ordered use_hash(d) full(d) full(e) noparallel(d) parallel(e 4) */
           >```
           > * 병렬 SQL이 시작되면 QC는 사용자가 지정한 병렬도(DOP, degree of parallelism)와 오퍼레이션 종류에 따라 하나 또는 두 개의 병렬 서버 집합(Server Set)을 할당한다. 우선 서버 풀(Parallel Execution Server Pool)로부터 필요한 만큼 서버 프로세스를 확보하고, 부족분은 새로 생성한다.
           > * QC는 각 병렬 서버에게 작업을 할당한다. 작업을 지시하고 일이 잘 진행되는지 관리감독하는 작업반장 역할이다.
           > * 병렬로 처리하도록 사용자가 지시하지 않은 테이블은 QC가 직접 처리한다. 예를 들어, 아래 실행계획에서 dept 테이블을 직렬로 읽어 병렬 서버에 전송하는 8~9번 오퍼레이션은 QC의 몫이다.
           > * QC는 각 병렬 서버로부터의 산출물을 통합하는 작업을 수행한다. 예를 들어 집계 함수(sum, count, avg, min, max 등)가 사용된 아래와 같은 병렬 쿼리를 수행할 때, 각 병렬 서버가 자신의 처리 범위 내에서 집계(4번 단계)한 값을 QC에게 전송(3번 단계)하면 QC가 최종 집계 작업을 수행(1번 단계)한다.
           > * QC는 쿼리의 최종 결과집합을 사용자에게 전송하며, DML일 때는 갱신 건수를 집계해서 전송해 준다. 쿼리 결과를 전송하는 단계에서 수행되는 스칼라 서브쿼리도 QC가 수행한다.
         + ##### 나. Intra-Operation Parallelism과 Inter-Operation Parallelism
           >```sql
           > /*+ full(고객) parallel(고객4) */
           > ```
           > * 서로 배타적인 범위를 독립적으로 동시에 처리하는 것을 ‘Intra-Operation Parallelism’이라고 한다. 첫 번째 서버 집합(P000~P003)에 속한 4개의 프로세스가 범위를 나눠 고객 데이터를 읽는 작업과, 두 번째 서버 집합 고객 데이터를 정렬하는 작업이 모두 여기에 속한다. 같은 서버 집합끼리는 서로 데이터를반대편 서버 집합에 분배하거나 정렬된 결과를 QC에게 전송하는 작업을 병렬로 동시에 진행하는 것을 ‘Inter-Operation Parallelism’이라고 하며, 이때는 항상 프로세스 간 통신이 발생한다.
           ![IMG](/images_files/SQL_410.jpg)
         + ##### 다. 테이블 큐
         + ##### 라. IN-OUT 오퍼레이션
         + ##### 마. 데이터 재분배
         + ##### 바. pq_distribute 힌트 활용
           + ###### 1) pq_distribute 힌트의 용도
           + ###### 2) pq_distribute 사용법
           + ###### 3) pq_distribute 힌트를 이용한 튜닝 사례
         + ##### 사. 병렬 처리 시 주의사항
           > * 동시 사용자 수가 적은 애플리케이션 환경(야간 배치 프로그램, DW, OLAP 등)에서 직렬로 처리할 때보다 성능 개선 효과가 확실할 때(→ 이 기준에 따르면 작은 테이블은 병렬 처리 대상에서 제외됨)
           > * OLTP성 시스템 환경이더라도 작업을 빨리 완료함으로써 직렬로 처리할 때보다 오히려 전체적인 시스템 리소스(CPU, Memory 등) 사용률을 감소시킬 수 있을 때(→ 수행 빈도가 높지 않음을 전제로)
           > * 병렬 DML 수행 시 Exclusive 모드 테이블 Lock이 걸리므로 트랜잭션이 활발한 주간에 절대 유의
     + ### 제6절 고급 SQL 활용
       + #### 1. CASE문 활용
       + #### 2. 데이터 복제 기법 활용
       + #### 3. Union All을 활용한 M:M 관계의 조인
       + #### 4. 페이징 처리
         + ##### 가. 일반적인 페이징 처리용 SQL
         + ##### 나. 뒤쪽 페이지까지 자주 조회할 때
         + ##### 다. Union All 활용
       + #### 5. 윈도우 함수 활용
         >  last_value(상태코드 ignore nulls)
       + #### 6. With 구문 활용
   + ## 제7장 Lock과 트랜잭션 동시성 제어
     + ### 제1절 Lock
       + #### 1. Lock 기본
         + ##### 가. Lock이란?
         + ##### 나. 공유 Lock과 배타적 Lock
           + ###### 1) 공유 Lock
           + ###### 2) 배타적 Lock
         + ##### 다. 블로킹과 교착상태
           + ###### 1) 블로킹
             > * 원자성을 훼손하지 않는 선에서 트랜잭션을 가능한 짧게 정의
             > * 같은 데이터를 갱신하는 트랜잭션이 동시에 수행되지 않도록 설계
             > * 무한정 기다리지 않도록 적절한 프로그래밍 기법을 도입(or update wait 3, update nowait)
           + ###### 2) 교착상태
             > *  테이블 접근 순서를 같게 처리하면 피할 수 있다. 
       + #### 2. SQL Server Lock
         + ##### 가. Lock 종류
           + ###### 1) 공유 Lock
           + ###### 2) 배타적 Lock
           + ###### 3) 갱신 Lock
           + ###### 4) 의도 Lock
             > ROW Lock을 상위 레벨 개체(페이지, 익스텐트, 테이블)까지 알려주는 Flag
           + ###### 5) 스키마 Lock
             > * 테이블 스키마 의존적 작업시 수행
             > * Sch-S(Schema Stability) : SQL을 컴파일하면서 오브젝트 스키마를 참조할 때 발생하며, 읽는 스키마 정보가 수정되거나 삭제되지 못하도록 함
             > * Sch-M(Schema Modification) : 테이블 구조를 변경하는 DDL 문을 수행할 때 발생하며, 수정 중인 스키마 정보를 다른 세션이 참조하지 못하도록 함
           + ###### 6) Bulk Update Lock
             > * 테이블 Lock의 일종으로, 테이블에 데이터를 Bulk Copy 할 때 발생한다. 병렬 데이터 로딩(Bulk Insert나 bcp 작업을 동시 수행)을 허용하지만 일반적인 트랜잭션 작업은 허용되지 않는다.
         + ##### 나. Lock 레벨과 Escalation
           ![IMG](/images_files/SQL_274.jpg)
           > * Lock Escalation
           > * 관리할 Lock 리소스가 정해진 임계치를 넘으면서 로우 레벨 락이 페이지, 익스텐트, 테이블 레벨 락으로 점점 확장되는 것을 말한다. 이는 SQL Server, DB2 UDB처럼 한정된 메모리 상에서 Lock 매니저를 통해 Lock 정보를 관리하는 DBMS에서 공통적으로 발생할 수 있는 현상이다. Locking 레벨이 낮을수록 동시성은 좋지만 관리해야 할 Lock 개수가 증가하기 때문에 더 많은 리소스를 소비한다. 반대로, Locking 레벨이 높을수록 적은 양의 Lock 리소스를 사용하지만 하나의 Lock으로 수많은 레코드를 한꺼번에 잠그기 때문에 동시성은 나빠진다.
         + ##### 다. Lock 호환성
           > * Sch-S는 Sch-M을 제외한 모든 Lock과 호환된다.
           > * Sch-M은 어떤 Lock과도 호환되지 않는다.
           ![img](/images_files/SQL_275.jpg)
       + #### 3. Oracle Lock
         + ##### 가. 로우 Lock
         + ##### 나. 테이블 Lock
           > * Row Share(RS)
           > * Row Exclusive(RX)
           > * Share(S)
           > * Share Row Exclusive(SRX)
           > * Exclusive(X)
           ![IMG](/images_files/SQL_276.jpg)
     + ### 제2절 트랜잭션
       + #### 1. 트랜잭션의 특징
         > * 원자성(Atomicity) : 트랜잭션은 더 이상 분해가 불가능한 업무의 최소단위이므로, 전부 처리되거나 아예 하나도 처리되지 않아야 한다.
         > * 일관성(Consistency) : 일관된 상태의 데이터베이스에서 하나의 트랜잭션을 성공적으로 완료하고 나면 그 데이터베이스는 여전히 일관된 상태여야 한다. 즉, 트랜잭션 실행의 결과로 데이터베이스 상태가 모순되지 않아야 한다.
         > * 격리성(Isolation) : 실행 중인 트랜잭션의 중간결과를 다른 트랜잭션이 접근할 수 없다.
         > * 영속성(Durability) : 트랜잭션이 일단 그 실행을 성공적으로 완료하면 그 결과는 데이터베이스에 영속적으로 저장된다.
       + #### 2. 트랜잭션 격리성
         + ##### 가. 낮은 단계의 격리성 수준에서 발생할 수 있는 현상들
           + ###### 1) Dirty Read
           + ###### 2) Non-Repeatable Read
             ![IMG](/images_files/SQL_277.jpg)
           + ###### 3) Phantom Read
             ![IMG](/images_files/SQL_278.jpg)
         + ##### 나. 트랜잭션 격리성 수준
           > * Read Uncommitted : 트랜잭션에서 처리 중인 아직 커밋되지 않은 데이터를 다른 트랜잭션이 읽는 것을 허용
           > * Read Committed : 커밋된 데이터만 읽도록 허용. Dirty Read 방지. Non-Repeatable Read와 Phantom Read 현상을 막지는 못한다.
           > * Repeatable Read : 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌는 현상을 방지. Phantom Read 현상을 막지는 못한다. 
           > * Serializable Read : 트랜잭션 내에서 쿼리를 두 번 이상 수행할 때, 첫 번째 쿼리에 있던 레코드가 사라지거나 값이 바뀌지 않음은 물론 새로운 레코드가 나타나지도 않는다.
           ![IMG](/images_files/SQL_279.jpg)
     + ### 제3절 동시성 제어
       + #### 1. 비관적 동시성 제어 vs. 낙관적 동시성 제어
         + ##### 가. 비관적 동시성 제어
           > SELECT FOR UPDATE 후 UPDATE NOWAIT, UPDATE WAIT 3
         + ##### 나. 낙관적 동시성 제어
           > SELECT 변경일시 후 UPDATE 변경일시(최종 변경일시가 앞서 읽은 값과 같은지 비교)
       + #### 2. 다중버전 동시성 제어
         + ##### 가. 일반적인 Locking 메커니즘의 문제점
         + ##### 나. 다중버전 동시성 제어
         + ##### 다. 문장수준 읽기 일관성
         + ##### 라. 트랜잭션 수준 읽기
         + ##### 마. Snapshot too old
           > * Undo 영역의 크기를 증가시킨다.
           > * 불필요하게 커밋을 자주 수행하지 않는다.
           > * fetch across commit 형태의 프로그램 작성을 피해 다른 방식으로 구현한다. ANSI 표준에 따르면 커밋 이전에 열려 있던 커서는 더는 Fetch 하면 안 된다. 다른 방?.
           > * 트랜잭션이 몰리는 시간대에 오래 걸리는 쿼리가 같이 수행되지 않도?로 나누어 읽고 단계적으로 실행할 수 있도록 코딩한다. Snapshot too old 발생 가능성을 줄일 뿐 아니라 문제가 발생했을 때 특정 부분부터 다시 시작할 수도 있어 유리하다. 물론 그렇게 해도 읽기 일관성에 문제가 없을 때에만 적용해야 한다.
           > * 오랜 시간에 걸쳐 같은 블록을 여러 번 방문하는 Nested Loop 형태의 조인문 또는 인덱스를 경유한 테이블 액세스를 수반하는 프로그램이 있는지 체크하고, 이를 회피할 수 있는 방법(조인 메소드 변경, Full Table Scan 등)을 찾는다.
           > * 소트 부하를 감수하더라도 order by 등을 강제로 삽입해 소트연산이 발생하도록 한다.
           > * 대량 업데이트 후에 곧바로 해당 테이블 또는 인덱스를 Full Scan 하도록 쿼리를 수행하는 것도 하나의 해결방법이 될 수 있다.
